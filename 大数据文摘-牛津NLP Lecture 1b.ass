[Script Info]
; Script generated by Aegisub 3.2.2
; http://www.aegisub.org/
Title: phpWEckUo
ScriptType: v4.00+
PlayDepth: 0
YCbCr Matrix: TV.601
PlayResX: 1280
PlayResY: 720

[Aegisub Project Garbage]
Audio File: ../../../Downloads/Deep Learning for NLP at Oxford 2017 - Lecture 1b  - Deep Neural Networks [Wang Ling]-DcVWSOesJho.mp4
Video File: ../../../Downloads/Deep Learning for NLP at Oxford 2017 - Lecture 1b  - Deep Neural Networks [Wang Ling]-DcVWSOesJho.mp4
Video AR Mode: 4
Video AR Value: 1.777778
Video Zoom Percent: 1.000000
Active Line: 262
Video Position: 21232

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,20,&H00FFFFFF,&H0300FFFF,&H00000000,&H02000000,0,0,0,0,100,100,0,0,1,2,1,2,10,10,10,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:00.00,0:00:03.00,Default,,0,0,0,,首先做个简单介绍
Dialogue: 0,0:00:03.00,0:00:05.48,Default,,0,0,0,,这位是Wang Ling
Dialogue: 0,0:00:05.48,0:00:09.85,Default,,0,0,0,,他在DeepMind的一个组内负责语义研究
Dialogue: 0,0:00:09.85,0:00:11.46,Default,,0,0,0,,Wang来自葡萄牙
Dialogue: 0,0:00:11.46,0:00:13.86,Default,,0,0,0,,并且已经获得了博士学位
Dialogue: 0,0:00:13.86,0:00:16.56,Default,,0,0,0,,Wang参加的是几年前的一个非常棒的
Dialogue: 0,0:00:16.56,0:00:19.83,Default,,0,0,0,,由美国卡耐基梅隆大学和里斯本
Dialogue: 0,0:00:19.83,0:00:22.80,Default,,0,0,0,,合作的博士学位项目
Dialogue: 0,0:00:22.80,0:00:24.84,Default,,0,0,0,,最近他和我们一起在DeepMind工作
Dialogue: 0,0:00:24.84,0:00:27.40,Default,,0,0,0,,专注于大量有趣的
Dialogue: 0,0:00:27.40,0:00:29.23,Default,,0,0,0,,有关深度学习和语义的问题
Dialogue: 0,0:00:29.23,0:00:32.23,Default,,0,0,0,,他为你们准备的是
Dialogue: 0,0:00:32.23,0:00:34.30,Default,,0,0,0,,一个非常棒的神经网络导论
Dialogue: 0,0:00:34.30,0:00:37.17,Default,,0,0,0,,所以我想由他来讲述今天的第一堂课程
Dialogue: 0,0:00:37.17,0:00:40.10,Default,,0,0,0,,谢谢大家
Dialogue: 0,0:00:40.10,0:00:42.55,Default,,0,0,0,,大家好 我叫Wang Ling
Dialogue: 0,0:00:42.55,0:00:46.43,Default,,0,0,0,,首先会介绍下神经网络
Dialogue: 0,0:00:46.43,0:00:49.23,Default,,0,0,0,,这是课程第一部分的大纲
Dialogue: 0,0:00:49.23,0:00:52.36,Default,,0,0,0,,所以你们能看到
Dialogue: 0,0:00:52.36,0:00:54.71,Default,,0,0,0,,这些是你所需要知道的数学知识
Dialogue: 0,0:00:54.71,0:00:56.55,Default,,0,0,0,,所以如果你对这些不了解
Dialogue: 0,0:00:56.55,0:00:59.46,Default,,0,0,0,,我会表示担心
Dialogue: 0,0:00:59.46,0:01:02.39,Default,,0,0,0,,所以当我们掌握了这些知识
Dialogue: 0,0:01:02.39,0:01:04.89,Default,,0,0,0,,我们会讲到深度学习和说说这些模型
Dialogue: 0,0:01:04.89,0:01:07.70,Default,,0,0,0,,这是一些最常见的模型
Dialogue: 0,0:01:07.70,0:01:10.07,Default,,0,0,0,,如果你希望从事深度学习
Dialogue: 0,0:01:10.07,0:01:11.34,Default,,0,0,0,,首先当我们在小学时
Dialogue: 0,0:01:11.34,0:01:13.82,Default,,0,0,0,,我们学习的第一件事就是数字
Dialogue: 0,0:01:13.82,0:01:15.81,Default,,0,0,0,,当我们学会的时候
Dialogue: 0,0:01:15.81,0:01:17.97,Default,,0,0,0,,每个人都很开心
Dialogue: 0,0:01:17.97,0:01:19.17,Default,,0,0,0,,因为当你想要回答问题的时候
Dialogue: 0,0:01:19.17,0:01:23.79,Default,,0,0,0,,你能用说来代替而不是给别人看这样数量的苹果
Dialogue: 0,0:01:23.79,0:01:26.00,Default,,0,0,0,,我们很容易就掌握了变量
Dialogue: 0,0:01:26.00,0:01:27.54,Default,,0,0,0,,我们并不是直接学习变量
Dialogue: 0,0:01:27.54,0:01:29.61,Default,,0,0,0,,我们通过学习 知道了4个苹果
Dialogue: 0,0:01:29.61,0:01:31.56,Default,,0,0,0,,和4个香蕉或5个香蕉不一样
Dialogue: 0,0:01:31.56,0:01:34.47,Default,,0,0,0,,这样我们能够
Dialogue: 0,0:01:34.47,0:01:36.42,Default,,0,0,0,,把数量和变量这两个不一样的方面联系起来
Dialogue: 0,0:01:36.42,0:01:40.32,Default,,0,0,0,,给他们贴上标签
Dialogue: 0,0:01:40.32,0:01:42.36,Default,,0,0,0,,然后我们学会了如何去运算这些数字
Dialogue: 0,0:01:42.36,0:01:44.90,Default,,0,0,0,,假如我们说Abby有4个苹果
Dialogue: 0,0:01:44.90,0:01:47.31,Default,,0,0,0,,给了Bert1个苹果
Dialogue: 0,0:01:47.31,0:01:50.71,Default,,0,0,0,,这样我们只需要做一个简单的减法
Dialogue: 0,0:01:50.71,0:01:53.61,Default,,0,0,0,,我们就能够直接说出
Dialogue: 0,0:01:53.61,0:01:55.32,Default,,0,0,0,,在她给出苹果后
Dialogue: 0,0:01:55.32,0:01:58.04,Default,,0,0,0,,她还会剩下3个苹果
Dialogue: 0,0:01:58.04,0:02:02.11,Default,,0,0,0,,于是我们学到了函数
Dialogue: 0,0:02:02.11,0:02:05.70,Default,,0,0,0,,现在Bert说
Dialogue: 0,0:02:05.70,0:02:08.92,Default,,0,0,0,,Abby每给他1个苹果
Dialogue: 0,0:02:08.92,0:02:11.22,Default,,0,0,0,,他要给她3个香蕉
Dialogue: 0,0:02:11.22,0:02:13.47,Default,,0,0,0,,所以这个函数是怎么样的？
Dialogue: 0,0:02:13.47,0:02:16.14,Default,,0,0,0,,一个最基本的函数是这样的
Dialogue: 0,0:02:16.14,0:02:19.67,Default,,0,0,0,,你会有一个X来作为输入
Dialogue: 0,0:02:19.67,0:02:22.22,Default,,0,0,0,,然后你需要给出一个输出
Dialogue: 0,0:02:22.22,0:02:24.67,Default,,0,0,0,,例如设为Y
Dialogue: 0,0:02:24.67,0:02:28.32,Default,,0,0,0,,简单来说X就是Abby会给Bert的苹果数量
Dialogue: 0,0:02:28.32,0:02:29.70,Default,,0,0,0,,Y就是Bert还给Abby的香蕉的数量
Dialogue: 0,0:02:29.70,0:02:32.28,Default,,0,0,0,,有趣的地方来了
Dialogue: 0,0:02:32.28,0:02:35.17,Default,,0,0,0,,现在我们已经有一个函数了
Dialogue: 0,0:02:35.17,0:02:38.69,Default,,0,0,0,,我们准确的知道对于任何一个X
Dialogue: 0,0:02:38.69,0:02:40.02,Default,,0,0,0,,Y的值会是多少
Dialogue: 0,0:02:40.02,0:02:43.17,Default,,0,0,0,,所以在这个例子里 如果X等于1
Dialogue: 0,0:02:43.17,0:02:45.51,Default,,0,0,0,,那么Abby会得到3个香蕉\N（译注：音频为苹果 应为讲师口误）
Dialogue: 0,0:02:45.51,0:02:48.87,Default,,0,0,0,,这样我们可以说这个函数
Dialogue: 0,0:02:48.87,0:02:51.75,Default,,0,0,0,,完美地预测了Bert在被赠送指定数量的苹果后
Dialogue: 0,0:02:51.75,0:02:54.27,Default,,0,0,0,,将会返还的香蕉数量
Dialogue: 0,0:02:54.27,0:02:56.70,Default,,0,0,0,,你们想一想
Dialogue: 0,0:02:56.70,0:02:59.26,Default,,0,0,0,,其实我们做的每件事情都可以看作一个函数
Dialogue: 0,0:02:59.26,0:03:01.80,Default,,0,0,0,,比如说翻译
Dialogue: 0,0:03:01.80,0:03:04.35,Default,,0,0,0,,就是这样一个过程
Dialogue: 0,0:03:04.35,0:03:06.15,Default,,0,0,0,,把X作为输入
Dialogue: 0,0:03:06.15,0:03:08.61,Default,,0,0,0,,在这里就是把英文语句作为输入
Dialogue: 0,0:03:08.61,0:03:10.32,Default,,0,0,0,,例如你想要翻译成西班牙语
Dialogue: 0,0:03:10.32,0:03:12.90,Default,,0,0,0,,你期望接收到西班牙语的句子
Dialogue: 0,0:03:12.90,0:03:14.61,Default,,0,0,0,,这就相当于对X做的变换
Dialogue: 0,0:03:14.61,0:03:17.85,Default,,0,0,0,,很多人都知道
Dialogue: 0,0:03:17.85,0:03:22.34,Default,,0,0,0,,DeepMind开发的围棋系统\N（译注：AlphaGo）
Dialogue: 0,0:03:22.34,0:03:25.80,Default,,0,0,0,,打败了世界上最顶尖的棋手
Dialogue: 0,0:03:25.80,0:03:28.01,Default,,0,0,0,,这样来说你就要去
Dialogue: 0,0:03:28.01,0:03:31.41,Default,,0,0,0,,建立这样一个函数
Dialogue: 0,0:03:31.41,0:03:35.19,Default,,0,0,0,,X代表了棋盘的现状
Dialogue: 0,0:03:35.19,0:03:38.76,Default,,0,0,0,,你想要知道如何走下一步棋
Dialogue: 0,0:03:38.76,0:03:41.26,Default,,0,0,0,,最后我想要做个图片分类
Dialogue: 0,0:03:41.26,0:03:44.98,Default,,0,0,0,,X代表着一张图片 就像图片中的这只猫
Dialogue: 0,0:03:44.98,0:03:46.17,Default,,0,0,0,,你想要来归类它到猫这一类
Dialogue: 0,0:03:46.17,0:03:51.69,Default,,0,0,0,,所以如果你能得到正确的函数
Dialogue: 0,0:03:51.69,0:03:54.15,Default,,0,0,0,,那你就能够解决这个问题
Dialogue: 0,0:03:54.15,0:03:57.13,Default,,0,0,0,,但是这里的问题是 如何得到正确的函数
Dialogue: 0,0:03:57.13,0:03:59.79,Default,,0,0,0,,也正是这个过程中最难的部分
Dialogue: 0,0:03:59.79,0:04:01.04,Default,,0,0,0,,以翻译为例
Dialogue: 0,0:04:01.04,0:04:03.15,Default,,0,0,0,,在最初的翻译系统中
Dialogue: 0,0:04:03.15,0:04:05.10,Default,,0,0,0,,人们并没有使用机器学习
Dialogue: 0,0:04:05.10,0:04:06.84,Default,,0,0,0,,他们只是写出了正确的规则
Dialogue: 0,0:04:06.84,0:04:08.85,Default,,0,0,0,,说这样就能构成一个句子
Dialogue: 0,0:04:08.85,0:04:11.86,Default,,0,0,0,,然后给出了句子的翻译
Dialogue: 0,0:04:11.86,0:04:13.60,Default,,0,0,0,,然而并没有翻译的很好
Dialogue: 0,0:04:13.60,0:04:15.26,Default,,0,0,0,,但是后来人们发现
Dialogue: 0,0:04:15.26,0:04:16.70,Default,,0,0,0,,如果你是用机器学习
Dialogue: 0,0:04:16.70,0:04:20.75,Default,,0,0,0,,你能够做的更好
Dialogue: 0,0:04:20.75,0:04:23.47,Default,,0,0,0,,我们来讨论另一种函数
Dialogue: 0,0:04:23.47,0:04:25.93,Default,,0,0,0,,现在Bert离开了
Dialogue: 0,0:04:25.93,0:04:28.15,Default,,0,0,0,,这边这位是Cookie Monster
Dialogue: 0,0:04:28.15,0:04:30.10,Default,,0,0,0,,Cookie Monster不告诉我们他要做什么
Dialogue: 0,0:04:30.10,0:04:32.69,Default,,0,0,0,,而是让我们去找出
Dialogue: 0,0:04:32.69,0:04:34.84,Default,,0,0,0,,在Abby给他苹果后
Dialogue: 0,0:04:34.84,0:04:37.26,Default,,0,0,0,,他需要给出多少数量的香蕉
Dialogue: 0,0:04:37.26,0:04:41.05,Default,,0,0,0,,Abby打算这么做
Dialogue: 0,0:04:41.05,0:04:42.67,Default,,0,0,0,,她给了Cookie Monster 1个苹果
Dialogue: 0,0:04:42.67,0:04:44.65,Default,,0,0,0,,她发现她什么也没得到
Dialogue: 0,0:04:44.65,0:04:47.74,Default,,0,0,0,,然后她给了他5个苹果
Dialogue: 0,0:04:47.74,0:04:51.07,Default,,0,0,0,,然后Cookie Monster给了她16个香蕉
Dialogue: 0,0:04:51.07,0:04:54.97,Default,,0,0,0,,然后她给了6个苹果
Dialogue: 0,0:04:54.97,0:04:57.87,Default,,0,0,0,,收到了20个香蕉
Dialogue: 0,0:04:57.87,0:05:01.81,Default,,0,0,0,,现在她没有更多苹果可以给了 但她想知道
Dialogue: 0,0:05:01.81,0:05:04.42,Default,,0,0,0,,如果她给了Cookie Monster 3个苹果
Dialogue: 0,0:05:04.42,0:05:08.47,Default,,0,0,0,,那么她会收到几个香蕉
Dialogue: 0,0:05:08.47,0:05:10.63,Default,,0,0,0,,所以来看看我们需要做的
Dialogue: 0,0:05:10.63,0:05:12.91,Default,,0,0,0,,在获得这样一个函数之前
Dialogue: 0,0:05:12.91,0:05:14.65,Default,,0,0,0,,我们需要加一个新类型的变量
Dialogue: 0,0:05:14.65,0:05:16.96,Default,,0,0,0,,我们称之为参数
Dialogue: 0,0:05:16.96,0:05:18.16,Default,,0,0,0,,我们的模型也需要参数
Dialogue: 0,0:05:18.16,0:05:22.12,Default,,0,0,0,,参数和输入输出的不同的地方在于
Dialogue: 0,0:05:22.12,0:05:23.89,Default,,0,0,0,,输入和输出是我们现实中观察到的
Dialogue: 0,0:05:23.89,0:05:25.41,Default,,0,0,0,,是已经发生的事情
Dialogue: 0,0:05:25.41,0:05:27.00,Default,,0,0,0,,它和现实相关
Dialogue: 0,0:05:27.00,0:05:29.16,Default,,0,0,0,,但是参数呢
Dialogue: 0,0:05:29.16,0:05:31.41,Default,,0,0,0,,它需要被估计
Dialogue: 0,0:05:31.41,0:05:34.39,Default,,0,0,0,,基于我们所看到的 我们需要找出这些参数
Dialogue: 0,0:05:34.39,0:05:37.96,Default,,0,0,0,,它们能给出正确的结果
Dialogue: 0,0:05:37.96,0:05:40.12,Default,,0,0,0,,现在我们来看这个问题
Dialogue: 0,0:05:40.12,0:05:43.15,Default,,0,0,0,,我们给Cookie Monster建模
Dialogue: 0,0:05:43.15,0:05:46.71,Default,,0,0,0,,那就是Y=WX+B
Dialogue: 0,0:05:46.71,0:05:49.03,Default,,0,0,0,,我们接下来要说的就是
Dialogue: 0,0:05:49.03,0:05:51.10,Default,,0,0,0,,数据就是我们所观察到的
Dialogue: 0,0:05:51.10,0:05:53.89,Default,,0,0,0,,我们想要使用这些数据训练出一个模型
Dialogue: 0,0:05:53.89,0:05:58.57,Default,,0,0,0,,我们用这样一个表格展示数据
Dialogue: 0,0:05:58.57,0:06:03.61,Default,,0,0,0,,表里有很多X和很多Y
Dialogue: 0,0:06:03.61,0:06:05.29,Default,,0,0,0,,现在我们有数据和模型
Dialogue: 0,0:06:05.29,0:06:08.56,Default,,0,0,0,,我们还需要什么呢？
Dialogue: 0,0:06:08.56,0:06:10.75,Default,,0,0,0,,我们现在需要找出参数w和b
Dialogue: 0,0:06:10.75,0:06:13.39,Default,,0,0,0,,那么我们如何做到这个呢？
Dialogue: 0,0:06:13.39,0:06:15.52,Default,,0,0,0,,我们先做这样一件事情
Dialogue: 0,0:06:15.52,0:06:21.13,Default,,0,0,0,,我会给你一些随机值 赋值给w和b
Dialogue: 0,0:06:21.13,0:06:24.80,Default,,0,0,0,,然后我们就会得到相应的y值
Dialogue: 0,0:06:24.80,0:06:27.54,Default,,0,0,0,,如果你把输入值放到现在的模型中
Dialogue: 0,0:06:27.54,0:06:32.38,Default,,0,0,0,,你就会得到相应的输出
Dialogue: 0,0:06:32.38,0:06:34.75,Default,,0,0,0,,现在我会用不一样的值再做一遍
Dialogue: 0,0:06:34.75,0:06:37.24,Default,,0,0,0,,将不同的值赋给w和b
Dialogue: 0,0:06:37.24,0:06:42.07,Default,,0,0,0,,然后你就会得到相应的y值
Dialogue: 0,0:06:42.07,0:06:43.48,Default,,0,0,0,,现在我们想要讨论的就是
Dialogue: 0,0:06:43.48,0:06:45.94,Default,,0,0,0,,哪一个模型更好
Dialogue: 0,0:06:45.94,0:06:48.26,Default,,0,0,0,,除非我们能回答这个问题 不然我们什么也干不了
Dialogue: 0,0:06:48.26,0:06:50.79,Default,,0,0,0,,因为我们没办法评估哪个模型更好
Dialogue: 0,0:06:50.79,0:06:52.05,Default,,0,0,0,,我们甚至不明白在这个任务中
Dialogue: 0,0:06:52.05,0:06:54.93,Default,,0,0,0,,一个模型比另一个更好是什么意思
Dialogue: 0,0:06:54.93,0:06:59.77,Default,,0,0,0,,所以我们该怎么做呢？
Dialogue: 0,0:06:59.77,0:07:01.63,Default,,0,0,0,,我们需要定义一个损失函数
Dialogue: 0,0:07:01.63,0:07:04.00,Default,,0,0,0,,这个损失函数是用来告诉我们
Dialogue: 0,0:07:04.00,0:07:07.48,Default,,0,0,0,,在已知变量w和d的情况下
Dialogue: 0,0:07:07.48,0:07:08.65,Default,,0,0,0,,模型的表现怎么样
Dialogue: 0,0:07:08.65,0:07:10.65,Default,,0,0,0,,一种损失函数是
Dialogue: 0,0:07:11.35,0:07:13.12,Default,,0,0,0,,就是我们所说的平方损失函数
Dialogue: 0,0:07:13.12,0:07:14.85,Default,,0,0,0,,在该函数中我们要用
Dialogue: 0,0:07:14.85,0:07:20.53,Default,,0,0,0,,真实Y值减去你的模型预测的Y值
Dialogue: 0,0:07:20.53,0:07:23.83,Default,,0,0,0,,并对其求平方和
Dialogue: 0,0:07:23.83,0:07:26.71,Default,,0,0,0,,所以如果你得到的数字越大
Dialogue: 0,0:07:26.71,0:07:28.33,Default,,0,0,0,,说明你的模型得出的答案和真实答案相差越远
Dialogue: 0,0:07:28.33,0:07:31.63,Default,,0,0,0,,现在我们将计算一下（一个例子）
Dialogue: 0,0:07:31.63,0:07:33.30,Default,,0,0,0,,我们取前两个值
Dialogue: 0,0:07:33.30,0:07:36.73,Default,,0,0,0,,计算它们的差值并取平方
Dialogue: 0,0:07:36.73,0:07:38.68,Default,,0,0,0,,对第二行和第三行也进行同样的计算
Dialogue: 0,0:07:38.68,0:07:41.26,Default,,0,0,0,,最后把三个数加起来
Dialogue: 0,0:07:41.26,0:07:46.15,Default,,0,0,0,,得到的数就是第一种模型的平方损失函数的值
Dialogue: 0,0:07:46.15,0:07:47.80,Default,,0,0,0,,即318
Dialogue: 0,0:07:47.80,0:07:49.93,Default,,0,0,0,,对第二个模型进行同样的计算
Dialogue: 0,0:07:49.93,0:07:51.72,Default,,0,0,0,,得数较小的模型更好一些
Dialogue: 0,0:07:51.72,0:07:53.80,Default,,0,0,0,,因为损失函数越小
Dialogue: 0,0:07:53.80,0:07:58.81,Default,,0,0,0,,离真实的解决方法更近
Dialogue: 0,0:07:58.81,0:08:02.80,Default,,0,0,0,,所以第二个模型更好
Dialogue: 0,0:08:02.80,0:08:05.38,Default,,0,0,0,,现在我们再一次提出这个问题
Dialogue: 0,0:08:05.38,0:08:09.85,Default,,0,0,0,,如何找出最合适的参数w和b
Dialogue: 0,0:08:09.85,0:08:11.97,Default,,0,0,0,,我们需要进行优化
Dialogue: 0,0:08:11.97,0:08:17.29,Default,,0,0,0,,你可以不停地尝试不同的b和w值
Dialogue: 0,0:08:17.29,0:08:19.24,Default,,0,0,0,,并找到能使你的损失函数最小的解
Dialogue: 0,0:08:19.24,0:08:22.75,Default,,0,0,0,,理想情况下 损失函数为零
Dialogue: 0,0:08:22.75,0:08:26.29,Default,,0,0,0,,这不是一个简单的问题
Dialogue: 0,0:08:26.29,0:08:28.27,Default,,0,0,0,,我们要找到
Dialogue: 0,0:08:28.27,0:08:30.72,Default,,0,0,0,,损失函数的最小值
Dialogue: 0,0:08:30.72,0:08:37.59,Default,,0,0,0,,通过变换参数w和b的值
Dialogue: 0,0:08:37.59,0:08:38.97,Default,,0,0,0,,我们只有两个变量
Dialogue: 0,0:08:38.97,0:08:41.44,Default,,0,0,0,,可以把他们画在坐标轴上
Dialogue: 0,0:08:41.44,0:08:44.77,Default,,0,0,0,,w是纵坐标 b是横坐标
Dialogue: 0,0:08:44.77,0:08:46.24,Default,,0,0,0,,我们先画出已知的第一个点
Dialogue: 0,0:08:46.24,0:08:47.88,Default,,0,0,0,,就从这里开始
Dialogue: 0,0:08:47.88,0:08:49.41,Default,,0,0,0,,我们把这个点画上去
Dialogue: 0,0:08:49.41,0:08:51.81,Default,,0,0,0,,就在坐标(2,2)的位置
Dialogue: 0,0:08:51.81,0:08:55.23,Default,,0,0,0,,怎样看起来更好呢
Dialogue: 0,0:08:55.23,0:08:59.52,Default,,0,0,0,,我们可以直接开始尝试不同的值
Dialogue: 0,0:08:59.52,0:09:02.67,Default,,0,0,0,,试试给w加1 计算对应的损失函数
Dialogue: 0,0:09:02.67,0:09:04.83,Default,,0,0,0,,我们再画一次图
Dialogue: 0,0:09:04.83,0:09:07.47,Default,,0,0,0,,现在我们得到了26 比之前更好
Dialogue: 0,0:09:07.47,0:09:12.42,Default,,0,0,0,,那么我们就保留这个
Dialogue: 0,0:09:12.42,0:09:14.64,Default,,0,0,0,,现在我们从新的坐标(3,2)开始
Dialogue: 0,0:09:14.64,0:09:16.08,Default,,0,0,0,,试着找另外的点
Dialogue: 0,0:09:16.08,0:09:18.87,Default,,0,0,0,,现在我们再给w加1 并再次计算损失函数
Dialogue: 0,0:09:18.87,0:09:21.92,Default,,0,0,0,,现在损失函数是136
Dialogue: 0,0:09:21.92,0:09:25.92,Default,,0,0,0,,136太大了 我们不采用这个点
Dialogue: 0,0:09:25.92,0:09:29.00,Default,,0,0,0,,那么现在我们试着增大b
Dialogue: 0,0:09:29.00,0:09:31.47,Default,,0,0,0,,并再次计算损失函数
Dialogue: 0,0:09:31.47,0:09:33.33,Default,,0,0,0,,这次的结果也不如之前的好
Dialogue: 0,0:09:33.33,0:09:35.25,Default,,0,0,0,,所以我们放弃这个点
Dialogue: 0,0:09:35.25,0:09:39.27,Default,,0,0,0,,然后我们试着减小b
Dialogue: 0,0:09:39.27,0:09:41.73,Default,,0,0,0,,结果稍微好了一些
Dialogue: 0,0:09:41.73,0:09:44.04,Default,,0,0,0,,我们又前进了一步 我们继续做这件事情
Dialogue: 0,0:09:44.04,0:09:47.31,Default,,0,0,0,,如果我们继续减小b
Dialogue: 0,0:09:47.31,0:09:50.79,Default,,0,0,0,,结果又会变得更好 所以我们可以继续减小
Dialogue: 0,0:09:50.79,0:09:52.44,Default,,0,0,0,,这个时候可以看到
Dialogue: 0,0:09:52.44,0:09:55.29,Default,,0,0,0,,如果我们继续向左走 损失函数会变大
Dialogue: 0,0:09:55.29,0:09:57.12,Default,,0,0,0,,如果向下走 损失函数也会变大
Dialogue: 0,0:09:57.12,0:09:59.82,Default,,0,0,0,,如果向上走 损失函数也会变大
Dialogue: 0,0:09:59.82,0:10:02.67,Default,,0,0,0,,所以技术上讲
Dialogue: 0,0:10:02.67,0:10:04.08,Default,,0,0,0,,算法会停在(4,0)这个坐标
Dialogue: 0,0:10:04.08,0:10:05.19,Default,,0,0,0,,因为找不到更好的结果了
Dialogue: 0,0:10:05.19,0:10:08.40,Default,,0,0,0,,那么这就是我们要找的吗？
Dialogue: 0,0:10:08.40,0:10:10.71,Default,,0,0,0,,答案是否定的
Dialogue: 0,0:10:10.71,0:10:12.57,Default,,0,0,0,,如果你采用图中蓝色的点
Dialogue: 0,0:10:12.57,0:10:16.02,Default,,0,0,0,,得到的损失函数是12
Dialogue: 0,0:10:16.02,0:10:19.89,Default,,0,0,0,,这比我们现有的函数损失要小
Dialogue: 0,0:10:19.89,0:10:22.40,Default,,0,0,0,,为什么我们没有找到这个点呢？
Dialogue: 0,0:10:22.40,0:10:28.20,Default,,0,0,0,,但是大家看看坐标轴上的点
Dialogue: 0,0:10:28.20,0:10:32.22,Default,,0,0,0,,你可以看到我们用来测试模型的样本点
Dialogue: 0,0:10:32.22,0:10:33.75,Default,,0,0,0,,其实稍微差一点
Dialogue: 0,0:10:33.75,0:10:36.69,Default,,0,0,0,,但是中间有一条路径是指向那个最佳点的
Dialogue: 0,0:10:36.69,0:10:41.88,Default,,0,0,0,,所以并不是我们的模型不能更好了
Dialogue: 0,0:10:41.88,0:10:43.26,Default,,0,0,0,,而是我们的优化不够好
Dialogue: 0,0:10:43.26,0:10:48.87,Default,,0,0,0,,这就是我们所说的机器学习中的（参数）搜索问题
Dialogue: 0,0:10:48.87,0:10:51.15,Default,,0,0,0,,即使模型可以做得更好
Dialogue: 0,0:10:51.15,0:10:52.80,Default,,0,0,0,,我们也找不到参数使模型变得更好
Dialogue: 0,0:10:52.80,0:10:56.33,Default,,0,0,0,,那么解决方法是什么呢？
Dialogue: 0,0:10:56.33,0:10:58.56,Default,,0,0,0,,第一种方法是
Dialogue: 0,0:10:58.56,0:11:00.66,Default,,0,0,0,,你可以让参数改变的步长更小
Dialogue: 0,0:11:00.66,0:11:03.24,Default,,0,0,0,,我们可以每次不给参数加1
Dialogue: 0,0:11:03.24,0:11:05.70,Default,,0,0,0,,而是增加一个很小很小的量
Dialogue: 0,0:11:05.70,0:11:07.64,Default,,0,0,0,,如果我们这样做了
Dialogue: 0,0:11:07.64,0:11:09.60,Default,,0,0,0,,你可以看到模型会慢慢地到达那个最佳点
Dialogue: 0,0:11:09.60,0:11:16.02,Default,,0,0,0,,有一件事情你不需要在训练模型的时候决定
Dialogue: 0,0:11:16.02,0:11:17.67,Default,,0,0,0,,就是你可以像我们一开始做的一样
Dialogue: 0,0:11:17.67,0:11:19.29,Default,,0,0,0,,用很大的步长
Dialogue: 0,0:11:19.29,0:11:21.14,Default,,0,0,0,,这样做的好处是
Dialogue: 0,0:11:21.14,0:11:23.82,Default,,0,0,0,,你可以更快地到达最佳点
Dialogue: 0,0:11:23.82,0:11:25.80,Default,,0,0,0,,如果你用很小的步长
Dialogue: 0,0:11:25.80,0:11:27.39,Default,,0,0,0,,训练模型将需要很长的时间
Dialogue: 0,0:11:27.39,0:11:29.31,Default,,0,0,0,,但是这样做的问题是
Dialogue: 0,0:11:29.31,0:11:31.43,Default,,0,0,0,,优化的结果或许没有小步长那么好
Dialogue: 0,0:11:31.43,0:11:34.14,Default,,0,0,0,,优化的结果或许没有小步长那么好
Dialogue: 0,0:11:34.14,0:11:36.57,Default,,0,0,0,,如果你采用小步长
Dialogue: 0,0:11:36.57,0:11:39.18,Default,,0,0,0,,你会获得更好的优化结果
Dialogue: 0,0:11:39.18,0:11:40.70,Default,,0,0,0,,但这会花费你很长很长的时间
Dialogue: 0,0:11:40.70,0:11:43.95,Default,,0,0,0,,在实际情况中 人们通常的做法是
Dialogue: 0,0:11:43.95,0:11:45.83,Default,,0,0,0,,先用很大的步长
Dialogue: 0,0:11:45.83,0:11:48.24,Default,,0,0,0,,一旦你的模型不再优化了
Dialogue: 0,0:11:48.24,0:11:50.73,Default,,0,0,0,,就减小步长继续优化
Dialogue: 0,0:11:50.73,0:11:52.08,Default,,0,0,0,,所以当你已经有了不错的结果 但你不能继续前进了的时候
Dialogue: 0,0:11:52.08,0:11:57.02,Default,,0,0,0,,就走得慢一些
Dialogue: 0,0:11:57.02,0:12:00.60,Default,,0,0,0,,如果我们这样做了
Dialogue: 0,0:12:00.60,0:12:02.94,Default,,0,0,0,,最终我们会得到最佳点
Dialogue: 0,0:12:02.94,0:12:04.80,Default,,0,0,0,,如果你一直使用这个方法
Dialogue: 0,0:12:04.80,0:12:06.66,Default,,0,0,0,,最终你会找到使损失函数为零的点
Dialogue: 0,0:12:06.66,0:12:08.88,Default,,0,0,0,,因为这只是一个函数
Dialogue: 0,0:12:08.88,0:12:10.26,Default,,0,0,0,,只要你的步长足够小
Dialogue: 0,0:12:10.26,0:12:13.29,Default,,0,0,0,,就一定会找到最佳点
Dialogue: 0,0:12:13.29,0:12:17.88,Default,,0,0,0,,所以如果我们取w为4 b为-4
Dialogue: 0,0:12:17.88,0:12:21.57,Default,,0,0,0,,每一个样本都会计算正确
Dialogue: 0,0:12:21.57,0:12:23.07,Default,,0,0,0,,这样我们就得到了正确的模型
Dialogue: 0,0:12:23.07,0:12:26.61,Default,,0,0,0,,参数为4和-4
Dialogue: 0,0:12:26.61,0:12:29.88,Default,,0,0,0,,你可以设想 如果Abby Cadabby给了Cookie Monster三个苹果
Dialogue: 0,0:12:29.88,0:12:32.22,Default,,0,0,0,,她就会得到八个香蕉
Dialogue: 0,0:12:32.22,0:12:39.27,Default,,0,0,0,,所以
Dialogue: 0,0:12:39.27,0:12:41.76,Default,,0,0,0,,现在的模型与应用场景比如图像分类相比
Dialogue: 0,0:12:41.76,0:12:42.77,Default,,0,0,0,,有多大不同呢？
Dialogue: 0,0:12:42.77,0:12:45.77,Default,,0,0,0,,不同点有两个
Dialogue: 0,0:12:45.77,0:12:47.73,Default,,0,0,0,,308\N00:12:47,730 --> 00:12:49,380\N但我们现在不需要担心的是
Dialogue: 0,0:12:49.38,0:12:51.99,Default,,0,0,0,,在图像分类中你不只有w和b两个参数
Dialogue: 0,0:12:51.99,0:12:54.93,Default,,0,0,0,,在图像分类中你不只有w和b两个参数
Dialogue: 0,0:12:54.93,0:12:56.79,Default,,0,0,0,,比如image classification
Dialogue: 0,0:12:56.79,0:12:59.43,Default,,0,0,0,,你的输入是一整张图像
Dialogue: 0,0:12:59.43,0:13:02.67,Default,,0,0,0,,每一个像素点都是一个特征
Dialogue: 0,0:13:02.67,0:13:04.70,Default,,0,0,0,,每个像素点都有一个相关的
Dialogue: 0,0:13:04.70,0:13:07.92,Default,,0,0,0,,如果你想给一个40*40像素的图片分类
Dialogue: 0,0:13:07.92,0:13:10.74,Default,,0,0,0,,你就有1600个不同的输入
Dialogue: 0,0:13:10.74,0:13:13.20,Default,,0,0,0,,如果是黑白图像
Dialogue: 0,0:13:13.20,0:13:16.80,Default,,0,0,0,,每个输入都有一个介于0和256的值
Dialogue: 0,0:13:16.80,0:13:21.75,Default,,0,0,0,,如果是rgb图像每个输入就有三个值
Dialogue: 0,0:13:21.75,0:13:24.36,Default,,0,0,0,,这就意味着
Dialogue: 0,0:13:24.36,0:13:26.92,Default,,0,0,0,,其实我们有很多很多变量
Dialogue: 0,0:13:26.92,0:13:28.50,Default,,0,0,0,,我们不能一个一个地优化这些变量
Dialogue: 0,0:13:28.50,0:13:30.69,Default,,0,0,0,,如果我只有两个变量的话
Dialogue: 0,0:13:30.69,0:13:32.35,Default,,0,0,0,,这个方法是可行的
Dialogue: 0,0:13:32.35,0:13:33.67,Default,,0,0,0,,如果有很多个变量就不可行了
Dialogue: 0,0:13:33.67,0:13:36.97,Default,,0,0,0,,总的来说
Dialogue: 0,0:13:36.97,0:13:39.10,Default,,0,0,0,,图像分类的数据集是用上百万个样本训练的
Dialogue: 0,0:13:39.10,0:13:41.85,Default,,0,0,0,,不是只有三个
Dialogue: 0,0:13:41.85,0:13:44.67,Default,,0,0,0,,这就意味着
Dialogue: 0,0:13:44.67,0:13:46.17,Default,,0,0,0,,如果你要计算损失函数
Dialogue: 0,0:13:46.17,0:13:48.06,Default,,0,0,0,,尝试很多不同的值会花费很长时间
Dialogue: 0,0:13:48.06,0:13:50.31,Default,,0,0,0,,尝试很多不同的值会花费很长时间
Dialogue: 0,0:13:50.31,0:13:52.44,Default,,0,0,0,,一般会花几个小时或几天
Dialogue: 0,0:13:52.44,0:13:54.93,Default,,0,0,0,,一般会花几个小时或几天
Dialogue: 0,0:13:54.93,0:13:56.58,Default,,0,0,0,,这取决于数据集的大小和你的模型有多大
Dialogue: 0,0:13:56.58,0:13:58.42,Default,,0,0,0,,所以我们不能支持
Dialogue: 0,0:13:58.42,0:14:00.80,Default,,0,0,0,,像这样通过计算那个函数
Dialogue: 0,0:14:00.80,0:14:03.61,Default,,0,0,0,,来测试每个不同的参数
Dialogue: 0,0:14:03.61,0:14:08.47,Default,,0,0,0,,所以我们如何尽可能
Dialogue: 0,0:14:08.47,0:14:10.54,Default,,0,0,0,,利用最小的计算量来做到这一点
Dialogue: 0,0:14:10.54,0:14:14.11,Default,,0,0,0,,我们重新从这一点开始
Dialogue: 0,0:14:14.11,0:14:16.72,Default,,0,0,0,,但是不是只是尝试随意赋值，而是定义一个称为hw的向量
Dialogue: 0,0:14:16.72,0:14:18.06,Default,,0,0,0,,但是不是只是尝试随意赋值，而是定义一个称为hw的向量
Dialogue: 0,0:14:18.06,0:14:21.45,Default,,0,0,0,,但是不是只是尝试随意赋值，而是定义一个称为hw的向量
Dialogue: 0,0:14:21.45,0:14:23.43,Default,,0,0,0,,假设它是在步长的方向上
Dialogue: 0,0:14:23.43,0:14:26.29,Default,,0,0,0,,我们现在将hw当做是1
Dialogue: 0,0:14:26.29,0:14:29.67,Default,,0,0,0,,我们想做的是
Dialogue: 0,0:14:29.67,0:14:32.52,Default,,0,0,0,,如果hw的当前值加上该向量的损失现在是26
Dialogue: 0,0:14:32.52,0:14:36.12,Default,,0,0,0,,如果hw的当前值加上该向量的损失现在是26
Dialogue: 0,0:14:36.12,0:14:38.29,Default,,0,0,0,,所以一旦我们执行这一步你就会得到26
Dialogue: 0,0:14:38.29,0:14:42.42,Default,,0,0,0,,我们可以计算以移动的距离为基础
Dialogue: 0,0:14:42.42,0:14:44.25,Default,,0,0,0,,我们可以计算以移动的距离为基础
Dialogue: 0,0:14:44.25,0:14:46.83,Default,,0,0,0,,朝这个方向上每单位会降低多少损失函数
Dialogue: 0,0:14:46.83,0:14:49.72,Default,,0,0,0,,朝这个方向上每单位会降低多少损失函数
Dialogue: 0,0:14:49.72,0:14:51.73,Default,,0,0,0,,基本上我称之为起作用了
Dialogue: 0,0:14:51.73,0:14:54.57,Default,,0,0,0,,它就像是通过你移动的距离来工作
Dialogue: 0,0:14:54.57,0:14:57.10,Default,,0,0,0,,所以如果我们一直减少这个
Dialogue: 0,0:14:57.10,0:14:58.83,Default,,0,0,0,,你就可以看到这个值
Dialogue: 0,0:14:58.83,0:15:01.77,Default,,0,0,0,,所以如果你一直减少这个
Dialogue: 0,0:15:01.77,0:15:04.36,Default,,0,0,0,,你会看到你得到的相当数量的回报是
Dialogue: 0,0:15:04.36,0:15:06.18,Default,,0,0,0,,它会收敛到一个值
Dialogue: 0,0:15:06.18,0:15:09.22,Default,,0,0,0,,这基本上是损失函数的关于w的导数的定义
Dialogue: 0,0:15:09.22,0:15:12.12,Default,,0,0,0,,这基本上是损失函数的关于w的导数的定义
Dialogue: 0,0:15:12.12,0:15:16.05,Default,,0,0,0,,这基本上是损失函数的关于w的导数的定义
Dialogue: 0,0:15:16.05,0:15:17.92,Default,,0,0,0,,一个函数关于那个变量的导数
Dialogue: 0,0:15:17.92,0:15:21.50,Default,,0,0,0,,一个函数关于那个变量的导数
Dialogue: 0,0:15:21.50,0:15:25.19,Default,,0,0,0,,如果你让它在那个方向上
Dialogue: 0,0:15:25.19,0:15:26.96,Default,,0,0,0,,使得步长为无穷小时函数值的变化程度
Dialogue: 0,0:15:26.96,0:15:29.36,Default,,0,0,0,,使得步长为无穷小时函数值的变化程度
Dialogue: 0,0:15:29.36,0:15:32.45,Default,,0,0,0,,这个的意思就是
Dialogue: 0,0:15:32.45,0:15:34.73,Default,,0,0,0,,我们只需要计算损失的导数
Dialogue: 0,0:15:34.73,0:15:36.29,Default,,0,0,0,,来知道我们实际上在哪个方向
Dialogue: 0,0:15:36.29,0:15:38.20,Default,,0,0,0,,能使得损失变得更小
Dialogue: 0,0:15:38.20,0:15:43.01,Default,,0,0,0,,能使得损失变得更小
Dialogue: 0,0:15:43.01,0:15:46.97,Default,,0,0,0,,所以你要意识到我们这里会得到函数关于w(的导数)的值
Dialogue: 0,0:15:46.97,0:15:49.88,Default,,0,0,0,,所以你要意识到我们这里会得到函数关于w(的导数)的值
Dialogue: 0,0:15:49.88,0:15:51.98,Default,,0,0,0,,就像是把它代入到提出的问题中
Dialogue: 0,0:15:51.98,0:15:54.59,Default,,0,0,0,,就像是把它代入到提出的问题中
Dialogue: 0,0:15:54.59,0:15:57.13,Default,,0,0,0,,然后可以看到如果我们重写并计算导数的值
Dialogue: 0,0:15:57.13,0:16:00.17,Default,,0,0,0,,然后可以看到如果我们重写并计算导数的值
Dialogue: 0,0:16:00.17,0:16:03.02,Default,,0,0,0,,它实际上会得到-104
Dialogue: 0,0:16:03.02,0:16:06.68,Default,,0,0,0,,计算只是为了以防万一
Dialogue: 0,0:16:06.68,0:16:10.76,Default,,0,0,0,,所以现在如果我想知道要用哪种方法
Dialogue: 0,0:16:10.76,0:16:12.26,Default,,0,0,0,,我不需要真的去计算损失函数
Dialogue: 0,0:16:12.26,0:16:14.18,Default,,0,0,0,,和尝试交互
Dialogue: 0,0:16:14.18,0:16:17.18,Default,,0,0,0,,我只需要计算导数
Dialogue: 0,0:16:17.18,0:16:19.67,Default,,0,0,0,,代入当前点的参数
Dialogue: 0,0:16:19.67,0:16:21.35,Default,,0,0,0,,我就可以知道我究竟该采取那种方法
Dialogue: 0,0:16:21.35,0:16:23.81,Default,,0,0,0,,我就可以知道我究竟该采取那种方法
Dialogue: 0,0:16:23.81,0:16:27.38,Default,,0,0,0,,例如在这个例子中的这两个
Dialogue: 0,0:16:27.38,0:16:29.51,Default,,0,0,0,,对于这里这个点我知道
Dialogue: 0,0:16:29.51,0:16:36.05,Default,,0,0,0,,如果hw取无穷小
Dialogue: 0,0:16:36.05,0:16:40.33,Default,,0,0,0,,我将会以每单位-104减小成本
Dialogue: 0,0:16:40.33,0:16:45.58,Default,,0,0,0,,我将会以每单位-104减小成本
Dialogue: 0,0:16:45.58,0:16:49.46,Default,,0,0,0,,如果我增大b 我将会自己减小
Dialogue: 0,0:16:49.46,0:16:51.32,Default,,0,0,0,,假设这些数字实际上是正数
Dialogue: 0,0:16:51.32,0:16:52.67,Default,,0,0,0,,这意味着
Dialogue: 0,0:16:52.67,0:16:55.22,Default,,0,0,0,,我只需要减小它
Dialogue: 0,0:16:55.22,0:16:59.39,Default,,0,0,0,,而不是去增大它
Dialogue: 0,0:16:59.39,0:17:01.58,Default,,0,0,0,,基本上这就是我们所说的梯度下降算法
Dialogue: 0,0:17:01.58,0:17:03.56,Default,,0,0,0,,基本上这就是我们所说的梯度下降算法
Dialogue: 0,0:17:03.56,0:17:06.43,Default,,0,0,0,,在每次迭代中我们代入当前参数的值
Dialogue: 0,0:17:06.43,0:17:08.41,Default,,0,0,0,,在每次迭代中我们代入当前参数的值
Dialogue: 0,0:17:08.41,0:17:11.27,Default,,0,0,0,,并减去那个参数的奖励函数加上alpha
Dialogue: 0,0:17:11.27,0:17:14.06,Default,,0,0,0,,并减去那个参数的奖励函数加上alpha
Dialogue: 0,0:17:14.06,0:17:15.62,Default,,0,0,0,,alpha是一个步长
Dialogue: 0,0:17:15.62,0:17:17.78,Default,,0,0,0,,如果你取大的alpha
Dialogue: 0,0:17:17.78,0:17:20.18,Default,,0,0,0,,你将获得最低速度
Dialogue: 0,0:17:20.18,0:17:22.13,Default,,0,0,0,,但是如果你技术性的取小一点它就会变好
Dialogue: 0,0:17:22.13,0:17:24.47,Default,,0,0,0,,但是如果你技术性的取小一点它就会变好
Dialogue: 0,0:17:24.47,0:17:26.63,Default,,0,0,0,,但是基本上你不需要试每一个参数
Dialogue: 0,0:17:26.63,0:17:27.74,Default,,0,0,0,,你现在只需要
Dialogue: 0,0:17:27.74,0:17:29.63,Default,,0,0,0,,每次迭代计算一次就可以
Dialogue: 0,0:17:29.63,0:17:32.99,Default,,0,0,0,,这几乎就是这样了
Dialogue: 0,0:17:32.99,0:17:34.37,Default,,0,0,0,,这个基本上是你需要了解的关于学习基础的机器学习的总结
Dialogue: 0,0:17:34.37,0:17:36.14,Default,,0,0,0,,这个基本上是你需要了解的关于学习基础的机器学习的总结
Dialogue: 0,0:17:36.14,0:17:37.52,Default,,0,0,0,,这个基本上是你需要了解的关于学习基础的机器学习的总结
Dialogue: 0,0:17:37.52,0:17:40.07,Default,,0,0,0,,你有你在这个世界上已经看到的东西的数据
Dialogue: 0,0:17:40.07,0:17:42.17,Default,,0,0,0,,你有你在这个世界上已经看到的东西的数据
Dialogue: 0,0:17:42.17,0:17:44.63,Default,,0,0,0,,这代表着如何去解决你的问题的真实凭据
Dialogue: 0,0:17:44.63,0:17:47.05,Default,,0,0,0,,这代表着如何去解决你的问题的真实凭据
Dialogue: 0,0:17:47.05,0:17:48.74,Default,,0,0,0,,你需要定义一个模型
Dialogue: 0,0:17:48.74,0:17:50.87,Default,,0,0,0,,在我们的情况下我们定义一个线性的模型
Dialogue: 0,0:17:50.87,0:17:52.52,Default,,0,0,0,,当你学习更多关于这个
Dialogue: 0,0:17:52.52,0:17:54.86,Default,,0,0,0,,很好的了解它的时候
Dialogue: 0,0:17:54.86,0:17:56.57,Default,,0,0,0,,你可以决定用什么样子的模型
Dialogue: 0,0:17:56.57,0:17:58.16,Default,,0,0,0,,这里有很多很多不同的方法你可以应用
Dialogue: 0,0:17:58.16,0:18:00.55,Default,,0,0,0,,这里有很多很多不同的方法你可以应用
Dialogue: 0,0:18:00.55,0:18:02.00,Default,,0,0,0,,最后有了模型你还需要一个损失函数
Dialogue: 0,0:18:02.00,0:18:04.96,Default,,0,0,0,,去了解这个模型有多好 有没有更好的
Dialogue: 0,0:18:04.96,0:18:08.42,Default,,0,0,0,,所有这些公认的数据部分
Dialogue: 0,0:18:08.42,0:18:11.12,Default,,0,0,0,,人们对于怎样定义更好的模型
Dialogue: 0,0:18:11.12,0:18:12.62,Default,,0,0,0,,怎样定义更好的损失函数
Dialogue: 0,0:18:12.62,0:18:14.15,Default,,0,0,0,,怎样定义更好的优化方法上付出了很大的工作量
Dialogue: 0,0:18:14.15,0:18:16.07,Default,,0,0,0,,所以在这些每一个领域中都有许多正在进行的研究
Dialogue: 0,0:18:16.07,0:18:17.60,Default,,0,0,0,,所以在这些每一个领域中都有许多正在进行的研究
Dialogue: 0,0:18:17.60,0:18:20.99,Default,,0,0,0,,一旦你有了所有的这些
Dialogue: 0,0:18:20.99,0:18:22.67,Default,,0,0,0,,然后你就可以都见你自己的系统
Dialogue: 0,0:18:22.67,0:18:24.67,Default,,0,0,0,,所以你尝试这个然后建立你的系统
Dialogue: 0,0:18:24.67,0:18:26.60,Default,,0,0,0,,它就会实现任何你想要的功能
Dialogue: 0,0:18:26.60,0:18:30.38,Default,,0,0,0,,它就会实现任何你想要的功能
Dialogue: 0,0:18:30.38,0:18:34.10,Default,,0,0,0,,现在我们开始深度学习
Dialogue: 0,0:18:34.10,0:18:35.80,Default,,0,0,0,,我们首先开始讨论的是非线性模型
Dialogue: 0,0:18:35.80,0:18:38.33,Default,,0,0,0,,我们首先开始讨论的是非线性模型
Dialogue: 0,0:18:38.33,0:18:41.99,Default,,0,0,0,,函数y=4x-4是线性的
Dialogue: 0,0:18:41.99,0:18:43.76,Default,,0,0,0,,所以苹果越多
Dialogue: 0,0:18:43.76,0:18:45.44,Default,,0,0,0,,你所能得到的也更多
Dialogue: 0,0:18:45.44,0:18:47.66,Default,,0,0,0,,如果它是成反比的
Dialogue: 0,0:18:47.66,0:18:49.19,Default,,0,0,0,,如你所见你会给出更多的苹果
Dialogue: 0,0:18:49.19,0:18:50.80,Default,,0,0,0,,有些情况下它也能与其他输入成比例
Dialogue: 0,0:18:50.80,0:18:53.69,Default,,0,0,0,,有些情况下它也能与其他输入成比例
Dialogue: 0,0:18:53.69,0:18:56.36,Default,,0,0,0,,但是问题是大多数现实生活中的现象不是线性的
Dialogue: 0,0:18:56.36,0:18:58.88,Default,,0,0,0,,但是问题是大多数现实生活中的现象不是线性的
Dialogue: 0,0:18:58.88,0:19:01.30,Default,,0,0,0,,但是问题是大多数现实生活中的现象不是线性的
Dialogue: 0,0:19:01.30,0:19:03.67,Default,,0,0,0,,所以举个例子这就像是如果我一直给他苹果
Dialogue: 0,0:19:03.67,0:19:05.51,Default,,0,0,0,,所以举个例子这就像是如果我一直给他苹果
Dialogue: 0,0:19:05.51,0:19:07.67,Default,,0,0,0,,他会用完香蕉而不能给我
Dialogue: 0,0:19:07.67,0:19:09.80,Default,,0,0,0,,他会用完香蕉而不能给我
Dialogue: 0,0:19:09.80,0:19:11.48,Default,,0,0,0,,所以他可能不能给我那么多香蕉
Dialogue: 0,0:19:11.48,0:19:16.79,Default,,0,0,0,,所以我们试着建立这个模型
Dialogue: 0,0:19:16.79,0:19:18.38,Default,,0,0,0,,所以Cookie Monster会说的是如果你给我太多苹果
Dialogue: 0,0:19:18.38,0:19:20.33,Default,,0,0,0,,我给不了你相当的香蕉
Dialogue: 0,0:19:20.33,0:19:21.77,Default,,0,0,0,,所以会存在一个点
Dialogue: 0,0:19:21.77,0:19:23.24,Default,,0,0,0,,我将会什么也得不到
Dialogue: 0,0:19:23.24,0:19:26.42,Default,,0,0,0,,之前我们的函数是像这样的
Dialogue: 0,0:19:26.42,0:19:28.61,Default,,0,0,0,,这是y 这是x
Dialogue: 0,0:19:28.61,0:19:30.02,Default,,0,0,0,,那些是我们已经画好的点
Dialogue: 0,0:19:30.02,0:19:34.01,Default,,0,0,0,,我们接下来要讨论画更多的点
Dialogue: 0,0:19:34.01,0:19:36.29,Default,,0,0,0,,我们接下来要讨论画更多的点
Dialogue: 0,0:19:36.29,0:19:38.24,Default,,0,0,0,,Abby将会给Cookie Monster9个苹果
Dialogue: 0,0:19:38.24,0:19:40.42,Default,,0,0,0,,但仍旧只得到20个香蕉
Dialogue: 0,0:19:40.42,0:19:43.04,Default,,0,0,0,,给出11个苹果但仍只能拿回20个香蕉
Dialogue: 0,0:19:43.04,0:19:46.42,Default,,0,0,0,,所以现在的问题是
Dialogue: 0,0:19:46.42,0:19:47.84,Default,,0,0,0,,你可以看到线性的函数不能构建模型
Dialogue: 0,0:19:47.84,0:19:50.84,Default,,0,0,0,,因为没有任何方法
Dialogue: 0,0:19:50.84,0:19:52.61,Default,,0,0,0,,可以让你画一条直线
Dialogue: 0,0:19:52.61,0:19:55.07,Default,,0,0,0,,没有遗漏一个的穿过所有的点
Dialogue: 0,0:19:55.07,0:19:57.23,Default,,0,0,0,,所以你能做的最好的事就是
Dialogue: 0,0:19:57.23,0:19:59.12,Default,,0,0,0,,定义一个函数使得它对于这些数据集是最佳的
Dialogue: 0,0:19:59.12,0:20:01.76,Default,,0,0,0,,定义一个函数使得它对于这些数据集是最佳的
Dialogue: 0,0:20:01.76,0:20:03.86,Default,,0,0,0,,所以你只能确保直线尽可能的接近这些每一个点
Dialogue: 0,0:20:03.86,0:20:05.57,Default,,0,0,0,,所以你只能确保直线尽可能的接近这些每一个点
Dialogue: 0,0:20:05.57,0:20:09.16,Default,,0,0,0,,这是一个机器学习的现象
Dialogue: 0,0:20:09.16,0:20:10.85,Default,,0,0,0,,我们称之为欠拟合
Dialogue: 0,0:20:10.85,0:20:13.25,Default,,0,0,0,,它不是你没有足够的数据
Dialogue: 0,0:20:13.25,0:20:14.60,Default,,0,0,0,,它只是无论你如何训练你的模型
Dialogue: 0,0:20:14.60,0:20:16.73,Default,,0,0,0,,无论你有多少数据
Dialogue: 0,0:20:16.73,0:20:18.04,Default,,0,0,0,,你都不能完美的给这个问题构建模型
Dialogue: 0,0:20:18.04,0:20:19.85,Default,,0,0,0,,所以这个模型是欠缺表现力的
Dialogue: 0,0:20:19.85,0:20:23.51,Default,,0,0,0,,所以这个模型是欠缺表现力的
Dialogue: 0,0:20:23.51,0:20:26.27,Default,,0,0,0,,事实上你需要了解这个问题
Dialogue: 0,0:20:26.27,0:20:28.30,Default,,0,0,0,,这就是为什么你需要学习非线性
Dialogue: 0,0:20:28.30,0:20:31.13,Default,,0,0,0,,我们想要做的是
Dialogue: 0,0:20:31.13,0:20:32.87,Default,,0,0,0,,学习一种像那样的函数
Dialogue: 0,0:20:32.87,0:20:35.96,Default,,0,0,0,,它直道那个点是直线
Dialogue: 0,0:20:35.96,0:20:38.60,Default,,0,0,0,,然后突然转向右边
Dialogue: 0,0:20:38.60,0:20:39.89,Default,,0,0,0,,事实上有没有什么方法让我们可以学习这种函数呢
Dialogue: 0,0:20:39.89,0:20:42.50,Default,,0,0,0,,所以我们来做这样的事
Dialogue: 0,0:20:42.50,0:20:44.12,Default,,0,0,0,,我们来使用不同的函数
Dialogue: 0,0:20:44.12,0:20:45.76,Default,,0,0,0,,我们有两个函数来进行建模
Dialogue: 0,0:20:45.76,0:20:48.79,Default,,0,0,0,,我们有两个函数来进行建模
Dialogue: 0,0:20:48.79,0:20:50.92,Default,,0,0,0,,其中一个函数使用参数w1
Dialogue: 0,0:20:50.92,0:20:53.40,Default,,0,0,0,,另外一个函数使用参数w2
Dialogue: 0,0:20:53.40,0:20:57.30,Default,,0,0,0,,函数里有一些二进制向量，例如S1和S2
Dialogue: 0,0:20:57.30,0:21:01.66,Default,,0,0,0,,我们希望在x<6时，S1等于1
Dialogue: 0,0:21:01.66,0:21:02.95,Default,,0,0,0,,我们希望在x<6是，S1等于1
Dialogue: 0,0:21:02.95,0:21:05.50,Default,,0,0,0,,S1会激活该呈上升趋势的函数（也就是W1*X + b1）
Dialogue: 0,0:21:05.50,0:21:12.77,Default,,0,0,0,,我们希望在x>=6时，S2等于1
Dialogue: 0,0:21:12.77,0:21:15.01,Default,,0,0,0,,函数（W2*X + b2）会保持大小不变
Dialogue: 0,0:21:15.01,0:21:18.69,Default,,0,0,0,,如果我们可以这样做，我们必须在此定义该函数
Dialogue: 0,0:21:18.69,0:21:20.14,Default,,0,0,0,,该函数在X<=6时可能为4X - 4
Dialogue: 0,0:21:20.14,0:21:21.52,Default,,0,0,0,,该函数在X<=6时可能为4X - 4
Dialogue: 0,0:21:21.52,0:21:23.00,Default,,0,0,0,,该函数在X<=6时可能为4X - 4
Dialogue: 0,0:21:23.00,0:21:25.55,Default,,0,0,0,,在X>6时保持不变
Dialogue: 0,0:21:25.85,0:21:27.90,Default,,0,0,0,,这表明我们确实可以学习S1和S2
Dialogue: 0,0:21:27.90,0:21:31.00,Default,,0,0,0,,让我们看一下怎样做这个工作
Dialogue: 0,0:21:31.00,0:21:35.02,Default,,0,0,0,,我猜你们可以想到的最明显的非线性函数
Dialogue: 0,0:21:35.02,0:21:37.37,Default,,0,0,0,,我猜你们可以想到的最明显的非线性函数
Dialogue: 0,0:21:37.37,0:21:39.50,Default,,0,0,0,,是我们称之为logistic sigmoid function的函数
Dialogue: 0,0:21:39.50,0:21:41.71,Default,,0,0,0,,嗯。。。
Dialogue: 0,0:21:41.71,0:21:44.80,Default,,0,0,0,,这里便是sigmoid函数。
Dialogue: 0,0:21:44.80,0:21:46.39,Default,,0,0,0,,基础形式：1/(1 + e^-t);t是你的输入
Dialogue: 0,0:21:46.39,0:21:48.71,Default,,0,0,0,,基础形式：1/(1 + e^-t);t是你的输入
Dialogue: 0,0:21:51.40,0:21:53.27,Default,,0,0,0,,而是看它的形式样子
Dialogue: 0,0:21:53.27,0:21:56.21,Default,,0,0,0,,在Y轴上，它的取值为（0,1）
Dialogue: 0,0:21:56.21,0:21:58.00,Default,,0,0,0,,在Y轴上，它的取值为（0,1）
Dialogue: 0,0:21:58.00,0:22:01.01,Default,,0,0,0,,它可以取0和1之间的任意值
Dialogue: 0,0:22:01.01,0:22:04.55,Default,,0,0,0,,当你的输入X趋向于负无穷时 它收敛于0
Dialogue: 0,0:22:04.55,0:22:08.59,Default,,0,0,0,,当你的输入X趋向于负无穷时 它收敛于0
Dialogue: 0,0:22:08.59,0:22:10.44,Default,,0,0,0,,当你的输入X趋向于负无穷时 它收敛于0
Dialogue: 0,0:22:10.44,0:22:14.00,Default,,0,0,0,,当X趋向于正无穷时 它收敛于1
Dialogue: 0,0:22:14.00,0:22:17.75,Default,,0,0,0,,这一特性让我们需要做很多事情
Dialogue: 0,0:22:17.75,0:22:19.58,Default,,0,0,0,,例如如何定义这些布尔运算符
Dialogue: 0,0:22:19.58,0:22:22.04,Default,,0,0,0,,一件你可能想做的事情也是我们在此想做的
Dialogue: 0,0:22:22.04,0:22:23.00,Default,,0,0,0,,一件你可能想做的事情也是我们想做的
Dialogue: 0,0:22:27.77,0:22:30.02,Default,,0,0,0,,它的值直接取0；
Dialogue: 0,0:22:30.02,0:22:31.97,Default,,0,0,0,,当输入值大于6时，
Dialogue: 0,0:22:31.97,0:22:35.15,Default,,0,0,0,,它的值取1。
Dialogue: 0,0:22:35.15,0:22:39.00,Default,,0,0,0,,在高中时你可能已经学过，
Dialogue: 0,0:22:39.00,0:22:41.18,Default,,0,0,0,,如果你取一个函数并把它的输入与一个很大的值相乘
Dialogue: 0,0:22:41.18,0:22:43.07,Default,,0,0,0,,如果你取一个函数并把它的输入与一个很大的值相乘
Dialogue: 0,0:22:43.07,0:22:44.00,Default,,0,0,0,,会使函数收缩
Dialogue: 0,0:22:44.00,0:22:46.52,Default,,0,0,0,,所以该函数看起来会使这个样子
Dialogue: 0,0:22:46.52,0:22:48.77,Default,,0,0,0,,随着你把sigmoid函数压缩得越来越紧凑
Dialogue: 0,0:22:48.77,0:22:50.99,Default,,0,0,0,,随着你把sigmoid函数压缩得越来越紧凑，
Dialogue: 0,0:22:50.99,0:22:54.40,Default,,0,0,0,,其会越来越接近接近ODD函数
Dialogue: 0,0:22:54.40,0:22:55.70,Default,,0,0,0,,ODD函数在某个输入范围内只有一个取值
Dialogue: 0,0:22:55.70,0:22:59.00,Default,,0,0,0,,ODD函数在某个输入范围内只有一个取值
Dialogue: 0,0:22:59.00,0:23:01.85,Default,,0,0,0,,如果你做了这项工作（压缩函数）
Dialogue: 0,0:23:01.85,0:23:04.76,Default,,0,0,0,,此时如果你计算x趋近于0.1时sigmoid函数的值
Dialogue: 0,0:23:04.76,0:23:06.47,Default,,0,0,0,,结果将非常接近1
Dialogue: 0,0:23:06.47,0:23:07.00,Default,,0,0,0,,结果将非常接近1
Dialogue: 0,0:23:07.81,0:23:11.66,Default,,0,0,0,,此时如果你计算x趋近于-0.1时sigmoid函数的值
Dialogue: 0,0:23:11.66,0:23:12.18,Default,,0,0,0,,结果将非常接近0
Dialogue: 0,0:23:12.18,0:23:15.74,Default,,0,0,0,,如果你想把此函数移到6的位置，
Dialogue: 0,0:23:15.74,0:23:17.21,Default,,0,0,0,,你必须在此减去你想要的平移量
Dialogue: 0,0:23:17.21,0:23:18.00,Default,,0,0,0,,你必须在此减去你想要的平移量
Dialogue: 0,0:23:19.13,0:23:21.80,Default,,0,0,0,,在这如果你想平移6个单位，根据乘数因子需要减去6000
Dialogue: 0,0:23:21.80,0:23:25.52,Default,,0,0,0,,在这如果你想平移6个单位，根据乘数因子需要减去6000
Dialogue: 0,0:23:25.52,0:23:28.65,Default,,0,0,0,,在这如果你想平移6个单位，根据乘数因子需要减去6000
Dialogue: 0,0:23:28.65,0:23:31.01,Default,,0,0,0,,现在我们有了一个特别的函数
Dialogue: 0,0:23:31.01,0:23:34.11,Default,,0,0,0,,该函数的输入如果落在X的左边，则取值为0
Dialogue: 0,0:23:34.11,0:23:37.02,Default,,0,0,0,,输入如果落在X的右边，则取值为1
Dialogue: 0,0:23:37.02,0:23:37.03,Default,,0,0,0,,568\N00:23:37,030 --> 00:23:39,140\N我在这尝试向你们展示如何更快地使用非线性模型
Dialogue: 0,0:23:39.14,0:23:40.50,Default,,0,0,0,,我在这尝试向你们展示如何更快地使用非线性模型
Dialogue: 0,0:23:40.50,0:23:42.32,Default,,0,0,0,,我的意思是你的模型最终必须学习一些这样的东西
Dialogue: 0,0:23:42.32,0:23:43.00,Default,,0,0,0,,我的意思是你的模型最终必须学习一些这样的东西
Dialogue: 0,0:23:43.00,0:23:47.21,Default,,0,0,0,,在很大程度上模型取决于优化器
Dialogue: 0,0:23:47.21,0:23:48.25,Default,,0,0,0,,你能够感受到这一点
Dialogue: 0,0:23:48.25,0:23:50.69,Default,,0,0,0,,但是你也看到使用该模型是可行的
Dialogue: 0,0:23:50.69,0:23:54.03,Default,,0,0,0,,现在我们拥有的是一个看起来这样子的模型
Dialogue: 0,0:23:54.03,0:23:54.04,Default,,0,0,0,,现在我们拥有的是一个看起来这样子的模型
Dialogue: 0,0:23:54.04,0:23:59.16,Default,,0,0,0,,这里有两个线性函数 并且它们被两个非线性函数相乘
Dialogue: 0,0:23:59.16,0:24:01.26,Default,,0,0,0,,这两个非线性函数可以在（0,1）取值
Dialogue: 0,0:24:01.26,0:24:03.20,Default,,0,0,0,,它们（线性函数）的触发条件是
Dialogue: 0,0:24:03.20,0:24:05.63,Default,,0,0,0,,x的取值是否趋近于6的左侧或者右侧
Dialogue: 0,0:24:05.63,0:24:07.00,Default,,0,0,0,,x的取值是否趋近于6的左侧或者右侧
Dialogue: 0,0:24:07.00,0:24:10.01,Default,,0,0,0,,这里只是向你展示它是如何工作的
Dialogue: 0,0:24:10.01,0:24:13.77,Default,,0,0,0,,如果你采用这里的数值（参数）
Dialogue: 0,0:24:13.77,0:24:17.00,Default,,0,0,0,,那么x等于5时其结果为16、20
Dialogue: 0,0:24:17.00,0:24:18.00,Default,,0,0,0,,那么x等于5时其结果为16、20
Dialogue: 0,0:24:18.00,0:24:21.41,Default,,0,0,0,,第一个sigmoid函数的（输入）值为1000
Dialogue: 0,0:24:21.41,0:24:24.21,Default,,0,0,0,,第二个sigmoid函数的（输入）值为-1000
Dialogue: 0,0:24:24.21,0:24:27.12,Default,,0,0,0,,basically this means that the you we\N这意味着你将激活第一个函数而不是第二个函数
Dialogue: 0,0:24:27.12,0:24:29.03,Default,,0,0,0,,这意味着你将激活第一个函数而不是第二个函数
Dialogue: 0,0:24:29.03,0:24:31.24,Default,,0,0,0,,所以第二个函数是无效的
Dialogue: 0,0:24:31.24,0:24:34.10,Default,,0,0,0,,所以我们得到y=16
Dialogue: 0,0:24:34.10,0:24:37.29,Default,,0,0,0,,如果我们把x的取值大于6
Dialogue: 0,0:24:37.29,0:24:40.65,Default,,0,0,0,,第一个函数与第二个函数的取值分别为32和20
Dialogue: 0,0:24:40.65,0:24:42.00,Default,,0,0,0,,第一个函数与第二个函数的取值分别为32和20
Dialogue: 0,0:24:42.00,0:24:46.09,Default,,0,0,0,,但是现在这两个激活函数将是另外的样子
Dialogue: 0,0:24:46.09,0:24:48.51,Default,,0,0,0,,so now the second\N第二个线性函数将被激活
Dialogue: 0,0:24:48.51,0:24:50.04,Default,,0,0,0,,第二个线性函数将被激活
Dialogue: 0,0:24:50.04,0:24:51.84,Default,,0,0,0,,并给出我们希望的值
Dialogue: 0,0:24:51.84,0:24:55.87,Default,,0,0,0,,你可以看到我们能够以这种方式定义该函数
Dialogue: 0,0:24:55.87,0:24:59.94,Default,,0,0,0,,现在我们使函数变得难一些
Dialogue: 0,0:24:59.94,0:25:02.17,Default,,0,0,0,,来看一下该值可以持续多久
Dialogue: 0,0:25:02.17,0:25:05.04,Default,,0,0,0,,现在我们这样假设：
Dialogue: 0,0:25:05.04,0:25:08.31,Default,,0,0,0,,如果Abby给他更多的苹果
Dialogue: 0,0:25:08.31,0:25:10.55,Default,,0,0,0,,他会变得烦躁 然后只给回一个香蕉
Dialogue: 0,0:25:10.55,0:25:12.27,Default,,0,0,0,,函数将会变成这样的形式
Dialogue: 0,0:25:12.27,0:25:16.38,Default,,0,0,0,,（此时）如果你把x的取值定为15、19
Dialogue: 0,0:25:16.38,0:25:17.12,Default,,0,0,0,,y的取值将为1
Dialogue: 0,0:25:17.12,0:25:19.00,Default,,0,0,0,,那么该如何学习该函数呢？
Dialogue: 0,0:25:19.00,0:25:24.14,Default,,0,0,0,,函数仍然假设所有的与我们想要的一样
Dialogue: 0,0:25:24.14,0:25:26.81,Default,,0,0,0,,我们想要实现的函数是这样的
Dialogue: 0,0:25:26.81,0:25:27.00,Default,,0,0,0,,
Dialogue: 0,0:25:27.00,0:25:30.47,Default,,0,0,0,,除了位于x小于6或者x大于15的两个已有sigmoid函数
Dialogue: 0,0:25:30.47,0:25:34.09,Default,,0,0,0,,除了位于x小于6或者x大于15的两个已有sigmoid函数
Dialogue: 0,0:25:34.09,0:25:37.38,Default,,0,0,0,,在6和15的区间内需要有另外一个sigmoid函数
Dialogue: 0,0:25:37.38,0:25:39.06,Default,,0,0,0,,在6和15的区间内需要有另外一个sigmoid函数
Dialogue: 0,0:25:39.06,0:25:41.37,Default,,0,0,0,,在6和15的区间内需要有另外一个sigmoid函数
Dialogue: 0,0:25:41.37,0:25:42.13,Default,,0,0,0,,在6和15的区间内需要有另外一个sigmoid函数
Dialogue: 0,0:25:42.13,0:25:44.75,Default,,0,0,0,,那么我们该如何做这项工作呢？
Dialogue: 0,0:25:44.75,0:25:48.75,Default,,0,0,0,,我们需要做的也就是
Dialogue: 0,0:25:48.75,0:25:53.00,Default,,0,0,0,,s1和s3不激活的时候，s2会激活
Dialogue: 0,0:25:53.00,0:25:56.28,Default,,0,0,0,,我们能够达到此目的的一种做法是
Dialogue: 0,0:25:56.28,0:25:59.90,Default,,0,0,0,,把s1和s3加入到s2中
Dialogue: 0,0:25:59.90,0:26:00.00,Default,,0,0,0,,所以s2依赖于s1和s3的取值
Dialogue: 0,0:26:01.23,0:26:04.42,Default,,0,0,0,,所以s2依赖于s1和s3的取值
Dialogue: 0,0:26:04.42,0:26:06.60,Default,,0,0,0,,例如。。。。哦，对不起（说错了）
Dialogue: 0,0:26:08.60,0:26:10.26,Default,,0,0,0,,如果你了解多层阶层分割
Dialogue: 0,0:26:10.26,0:26:12.39,Default,,0,0,0,,如果你了解多层阶层分割
Dialogue: 0,0:26:12.39,0:26:15.55,Default,,0,0,0,,s1和s3是第一层感知机
Dialogue: 0,0:26:15.55,0:26:18.58,Default,,0,0,0,,s2是第二层感知机
Dialogue: 0,0:26:18.58,0:26:20.19,Default,,0,0,0,,因为它（s2）依赖于第一层的结果
Dialogue: 0,0:26:20.19,0:26:21.97,Default,,0,0,0,,因为它（s2）依赖于第一层的结果
Dialogue: 0,0:26:22.97,0:26:26.04,Default,,0,0,0,,我们可以按照上面那样做来达到目的
Dialogue: 0,0:26:26.04,0:26:28.17,Default,,0,0,0,,我们可以按照上面那样做来达到目的
Dialogue: 0,0:26:28.17,0:26:32.64,Default,,0,0,0,,例如我们使用-1000s1 - 1000s3
Dialogue: 0,0:26:32.64,0:26:34.23,Default,,0,0,0,,那么使s2为正或者是比较大的值的唯一方法是
Dialogue: 0,0:26:34.23,0:26:39.24,Default,,0,0,0,,s1和s3全部为零
Dialogue: 0,0:26:39.24,0:26:42.36,Default,,0,0,0,,s1和s3全部为零
Dialogue: 0,0:26:42.36,0:26:45.66,Default,,0,0,0,,如果它们中任意一个不为零
Dialogue: 0,0:26:45.66,0:26:48.27,Default,,0,0,0,,那么s2的值将为负
Dialogue: 0,0:26:48.27,0:26:51.00,Default,,0,0,0,,因为它的偏移量是500
Dialogue: 0,0:26:51.00,0:26:53.31,Default,,0,0,0,,我们把它作为例子来看一下函数值会是什么
Dialogue: 0,0:26:53.31,0:26:54.89,Default,,0,0,0,,我们把它作为例子来看一下函数值会是什么
Dialogue: 0,0:26:54.89,0:26:59.00,Default,,0,0,0,,在第一行我们分别会得到40 、20 、1
Dialogue: 0,0:26:59.67,0:27:01.86,Default,,0,0,0,,这里我们看到它俩（s1和s3）都没有激活
Dialogue: 0,0:27:01.86,0:27:05.55,Default,,0,0,0,,它们的值为 0
Dialogue: 0,0:27:05.55,0:27:07.65,Default,,0,0,0,,如果我们给它们（s1和s3）加上500
Dialogue: 0,0:27:07.65,0:27:09.54,Default,,0,0,0,,我们会得到很高的一个值 那么s2的值为 1
Dialogue: 0,0:27:09.54,0:27:10.20,Default,,0,0,0,,我们会得到很高的一个值 那么s2的值为 1
Dialogue: 0,0:27:10.20,0:27:14.55,Default,,0,0,0,,中间的函数将会激活并给出那个区间的正确值
Dialogue: 0,0:27:14.55,0:27:17.50,Default,,0,0,0,,中间的函数将会激活并给出那个区间的正确值
Dialogue: 0,0:27:17.54,0:27:21.29,Default,,0,0,0,,如果我们取19这个数
Dialogue: 0,0:27:21.29,0:27:23.73,Default,,0,0,0,,也将会得到我们想要的结果
Dialogue: 0,0:27:23.73,0:27:25.04,Default,,0,0,0,,也将会得到我们想要的结果
Dialogue: 0,0:27:25.04,0:27:27.39,Default,,0,0,0,,此时你希望第三个函数激活
Dialogue: 0,0:27:27.39,0:27:31.38,Default,,0,0,0,,第一层的sigmoid函数会给出 0 和 1
Dialogue: 0,0:27:31.38,0:27:32.78,Default,,0,0,0,,第一层的sigmoid函数会给出 0 和 1
Dialogue: 0,0:27:33.78,0:27:36.29,Default,,0,0,0,,而且因为第二个值（s3的结果）等于 1  该值（s2的输入）将为 -500
Dialogue: 0,0:27:36.29,0:27:37.00,Default,,0,0,0,,s2会等于 0
Dialogue: 0,0:27:37.80,0:27:39.00,Default,,0,0,0,,所以第三部分会激活
Dialogue: 0,0:27:39.00,0:27:44.82,Default,,0,0,0,,你可以看到通过这样做你确实得到了正确的函数
Dialogue: 0,0:27:44.82,0:27:45.58,Default,,0,0,0,,你可以看到通过这样做你确实得到了正确的函数
Dialogue: 0,0:27:45.58,0:27:50.00,Default,,0,0,0,,你可以把你能够定义的每个函数看得很清楚
Dialogue: 0,0:27:50.00,0:27:52.00,Default,,0,0,0,,你可以任意使用这些间隔定义函数
Dialogue: 0,0:27:51.24,0:27:55.67,Default,,0,0,0,,你可以记住每个参考坐标轴
Dialogue: 0,0:27:52.97,0:27:57.60,Default,,0,0,0,,你实际上可以明确地记住每个轴
Dialogue: 0,0:27:57.60,0:28:00.54,Default,,0,0,0,,亦或者是数据的位置及其他被压缩的一些东西
Dialogue: 0,0:28:00.54,0:28:02.58,Default,,0,0,0,,亦或者是数据的位置及其他被压缩的一些东西
Dialogue: 0,0:28:02.58,0:28:04.80,Default,,0,0,0,,因此 一旦你用方程式去定义一个包含万物的网络 实际上会造成很多混乱
Dialogue: 0,0:28:04.80,0:28:06.18,Default,,0,0,0,,因此 一旦你用方程式去定义一个包含万物的网络 实际上会造成很多混乱
Dialogue: 0,0:28:06.18,0:28:09.33,Default,,0,0,0,,因此 一旦你用方程式去定义一个包含万物的网络 实际上会造成很多混乱
Dialogue: 0,0:28:09.33,0:28:11.40,Default,,0,0,0,,因此人们所做的就是将你已经做过的和你标记为有价值的纳入你的网络
Dialogue: 0,0:28:11.40,0:28:13.53,Default,,0,0,0,,因此人们所做的就是将你已经做过的和你标记为有价值的纳入你的网络
Dialogue: 0,0:28:13.53,0:28:15.35,Default,,0,0,0,,因此人们所做的就是将你已经做过的和你标记为有价值的纳入你的网络
Dialogue: 0,0:28:15.35,0:28:18.00,Default,,0,0,0,,因此人们所做的就是将你已经做过的和你标记为有价值的纳入你的网络
Dialogue: 0,0:28:18.00,0:28:21.96,Default,,0,0,0,,例如索引到S1 如果这意味着S1是X的线性组合
Dialogue: 0,0:28:21.96,0:28:24.72,Default,,0,0,0,,例如索引到S1 如果这意味着S1是X的线性组合
Dialogue: 0,0:28:24.72,0:28:28.08,Default,,0,0,0,,例如索引到S1 如果这意味着S1是X的线性组合
Dialogue: 0,0:28:28.08,0:28:32.22,Default,,0,0,0,,例如索引到S1 如果这意味着S1是X的线性组合
Dialogue: 0,0:28:32.22,0:28:36.57,Default,,0,0,0,,因此你也可以为S2做同样的事情 同理S3
Dialogue: 0,0:28:36.57,0:28:39.78,Default,,0,0,0,,因此你也可以为S2做同样的事情 同理S3
Dialogue: 0,0:28:39.78,0:28:43.53,Default,,0,0,0,,因为S2依赖于S1和S3 你可以说你在S1 S2和S3之间构建了联系
Dialogue: 0,0:28:43.53,0:28:49.62,Default,,0,0,0,,因为S2依赖于S1和S3 你可以说你在S1 S2和S3之间构建了联系
Dialogue: 0,0:28:49.62,0:28:51.66,Default,,0,0,0,,如果你想知道每层感知器的功能
Dialogue: 0,0:28:51.66,0:28:55.35,Default,,0,0,0,,第一层只能学习边界条件
Dialogue: 0,0:28:55.35,0:28:57.51,Default,,0,0,0,,就如这个X小于这个数字
Dialogue: 0,0:28:57.51,0:28:59.70,Default,,0,0,0,,就如这个X小于这个数字
Dialogue: 0,0:28:59.70,0:29:03.03,Default,,0,0,0,,又如这个X不等于某个数字
Dialogue: 0,0:29:03.03,0:29:05.10,Default,,0,0,0,,然而随后的感知器层可以
Dialogue: 0,0:29:05.10,0:29:08.25,Default,,0,0,0,,学习数值区间
Dialogue: 0,0:29:08.25,0:29:09.72,Default,,0,0,0,,因此你可以使第二层与第一层结合来真正学习一些东西
Dialogue: 0,0:29:09.72,0:29:12.82,Default,,0,0,0,,因此你可以使第二层与第一层结合来真正学习一些东西
Dialogue: 0,0:29:12.82,0:29:15.46,Default,,0,0,0,,因此你可以使第二层与第一层结合来真正学习一些东西
Dialogue: 0,0:29:15.46,0:29:16.92,Default,,0,0,0,,正如图中这样
Dialogue: 0,0:29:16.92,0:29:20.25,Default,,0,0,0,,你也可以让它学习的更多
Dialogue: 0,0:29:20.25,0:29:21.72,Default,,0,0,0,,所以一个多层感知器有很多种可以学习越来越复杂条件的方式
Dialogue: 0,0:29:21.72,0:29:25.76,Default,,0,0,0,,所以一个多层感知器有很多种可以学习越来越复杂条件的方式
Dialogue: 0,0:29:25.76,0:29:29.64,Default,,0,0,0,,当你定义了一个多层感知器后 我一定会先确定小的或者出现频率高的数据
Dialogue: 0,0:29:29.64,0:29:31.35,Default,,0,0,0,,当你定义了一个多层感知器后 我一定会先确定小的或者出现频率高的数据
Dialogue: 0,0:29:31.35,0:29:33.46,Default,,0,0,0,,因此你可以自己定义多层感知器的每层中所需的单位数，因此你可以在这里进行测试输入
Dialogue: 0,0:29:33.46,0:29:36.02,Default,,0,0,0,,因此你可以自己定义多层感知器的每层中所需的单位数，因此你可以在这里进行测试输入
Dialogue: 0,0:29:36.02,0:29:38.67,Default,,0,0,0,,因此你可以自己定义多层感知器的每层中所需的单位数，因此你可以在这里进行测试输入
Dialogue: 0,0:29:38.67,0:29:40.09,Default,,0,0,0,,第一层将会学习输入数字的特点
Dialogue: 0,0:29:40.09,0:29:42.22,Default,,0,0,0,,第二层将会学习输入数字特点之间的联系
Dialogue: 0,0:29:42.22,0:29:43.84,Default,,0,0,0,,第二层将会学习输入数字特点之间的联系
Dialogue: 0,0:29:43.84,0:29:46.47,Default,,0,0,0,,因此你可以组合输入的特征
Dialogue: 0,0:29:46.47,0:29:49.47,Default,,0,0,0,,因此你可以组合输入的特征
Dialogue: 0,0:29:49.47,0:29:51.46,Default,,0,0,0,,就如是否这些特征都被判断 还是是否这些特征在同一时间被分开判断或是其中某个特征被判断
Dialogue: 0,0:29:51.46,0:29:53.76,Default,,0,0,0,,就如是否这些特征都被判断 还是是否这些特征在同一时间被分开判断或是其中某个特征被判断
Dialogue: 0,0:29:53.76,0:29:56.25,Default,,0,0,0,,就如是否这些特征都被判断 还是是否这些特征在同一时间被分开判断或是其中某个特征被判断
Dialogue: 0,0:29:56.25,0:29:59.04,Default,,0,0,0,,通过这样做你可以基本学习到这些功能
Dialogue: 0,0:29:59.04,0:30:00.72,Default,,0,0,0,,看起来就像这样一样
Dialogue: 0,0:30:00.72,0:30:03.00,Default,,0,0,0,,当然 一个神经网络中不太可能会看见这些高数值
Dialogue: 0,0:30:03.00,0:30:05.97,Default,,0,0,0,,当然 一个神经网络中不太可能会看见这些高数值
Dialogue: 0,0:30:05.97,0:30:07.35,Default,,0,0,0,,但这就是一个粗略的例子
Dialogue: 0,0:30:07.35,0:30:09.78,Default,,0,0,0,,关于你如何完成感知器或者达到结束条件的例子
Dialogue: 0,0:30:09.78,0:30:14.49,Default,,0,0,0,,关于你如何完成感知器或者达到结束条件的例子
Dialogue: 0,0:30:14.49,0:30:17.25,Default,,0,0,0,,不要认为一个两层的多层感知器就无法完成任务
Dialogue: 0,0:30:17.25,0:30:20.25,Default,,0,0,0,,不要认为一个两层的多层感知器就无法完成任务
Dialogue: 0,0:30:20.25,0:30:22.89,Default,,0,0,0,,其实第三层就是前两层的异或连接 异或连接就是两者相同 则为一
Dialogue: 0,0:30:22.89,0:30:25.02,Default,,0,0,0,,两者不同 则为零
Dialogue: 0,0:30:25.02,0:30:27.46,Default,,0,0,0,,你可以使用异或的定义或者使用和、或的连接来实际上完成第三层
Dialogue: 0,0:30:27.46,0:30:30.19,Default,,0,0,0,,你可以使用异或的定义或者使用和、或的连接来实际上完成第三层
Dialogue: 0,0:30:30.19,0:30:31.86,Default,,0,0,0,,你可以使用异或的定义或者使用和、或的连接来实际上完成第三层
Dialogue: 0,0:30:31.86,0:30:33.75,Default,,0,0,0,,一旦你有了这样的思想
Dialogue: 0,0:30:33.75,0:30:35.49,Default,,0,0,0,,你的感知器可以学习任何你想要的条件
Dialogue: 0,0:30:35.49,0:30:37.53,Default,,0,0,0,,我们可以回想起某种通用逼近器的方式
Dialogue: 0,0:30:37.53,0:30:40.05,Default,,0,0,0,,我们可以回想起某种通用逼近器的方式
Dialogue: 0,0:30:40.05,0:30:42.22,Default,,0,0,0,,因为如果它有足够的单元
Dialogue: 0,0:30:42.22,0:30:44.13,Default,,0,0,0,,并且它有三层以上
Dialogue: 0,0:30:44.13,0:30:46.53,Default,,0,0,0,,那么它就可以学习你可以学习的任何功能
Dialogue: 0,0:30:46.53,0:30:49.86,Default,,0,0,0,,这就是多层感知器的学习能力
Dialogue: 0,0:30:49.86,0:30:50.77,Default,,0,0,0,,这就是多层感知器的学习能力
Dialogue: 0,0:30:50.77,0:30:53.32,Default,,0,0,0,,但问题在于
Dialogue: 0,0:30:53.32,0:30:54.58,Default,,0,0,0,,这并不意味着你将学习到正确的功能
Dialogue: 0,0:30:54.58,0:30:55.48,Default,,0,0,0,,所以即使你可以学习任何功能
Dialogue: 0,0:30:55.48,0:30:58.87,Default,,0,0,0,,因为你可以有这么多的条件
Dialogue: 0,0:30:58.87,0:31:00.91,Default,,0,0,0,,你也仅仅只能学习像这样的功能
Dialogue: 0,0:31:00.91,0:31:03.04,Default,,0,0,0,,你也仅仅只能学习像这样的功能
Dialogue: 0,0:31:03.04,0:31:05.80,Default,,0,0,0,,因此他有可能产生不了你期望的行为
Dialogue: 0,0:31:05.80,0:31:07.12,Default,,0,0,0,,因此他有可能产生不了你期望的行为
Dialogue: 0,0:31:07.12,0:31:10.39,Default,,0,0,0,,因此举例来说
Dialogue: 0,0:31:10.39,0:31:12.46,Default,,0,0,0,,怎么会这样呢
Dialogue: 0,0:31:12.46,0:31:14.35,Default,,0,0,0,,从我的角度来看它只是记住每一个答案
Dialogue: 0,0:31:14.35,0:31:17.35,Default,,0,0,0,,从我的角度来看它只是记住每一个答案
Dialogue: 0,0:31:17.35,0:31:20.17,Default,,0,0,0,,因此我们只需一个网络
Dialogue: 0,0:31:20.17,0:31:25.12,Default,,0,0,0,,如果X比1大 就产生第一个输出
Dialogue: 0,0:31:25.12,0:31:28.60,Default,,0,0,0,,如果X介于5和6之间 就产生如图所示的输出
Dialogue: 0,0:31:28.60,0:31:31.54,Default,,0,0,0,,如果X介于5和6之间 就产生如图所示的输出
Dialogue: 0,0:31:31.54,0:31:34.32,Default,,0,0,0,,如果X大于6 就产生输出20
Dialogue: 0,0:31:34.32,0:31:38.02,Default,,0,0,0,,如果X大于6 就产生输出20
Dialogue: 0,0:31:38.02,0:31:39.67,Default,,0,0,0,,基本说来网络所学习到的仅仅只是记住每一个输入所对应的输出是什么
Dialogue: 0,0:31:39.67,0:31:41.50,Default,,0,0,0,,基本说来网络所学习到的仅仅只是记住每一个输入所对应的输出是什么
Dialogue: 0,0:31:41.50,0:31:43.66,Default,,0,0,0,,基本说来网络所学习到的仅仅只是记住每一个输入所对应的输出是什么
Dialogue: 0,0:31:43.66,0:31:45.22,Default,,0,0,0,,因此网络没有学习到任何东西 仅仅只是记住你的数据
Dialogue: 0,0:31:45.22,0:31:48.04,Default,,0,0,0,,因此这样的网络并不是太有用
Dialogue: 0,0:31:48.04,0:31:50.20,Default,,0,0,0,,但是如果你给你的网络足够的层数 它也有可能仅仅做到这一点
Dialogue: 0,0:31:50.20,0:31:53.56,Default,,0,0,0,,但是如果你给你的网络足够的层数 它也有可能仅仅做到这一点
Dialogue: 0,0:31:53.56,0:31:55.12,Default,,0,0,0,,这就是我们所说在机械学习中的过拟合问题
Dialogue: 0,0:31:55.12,0:31:57.61,Default,,0,0,0,,这就是我们所说在机械学习中的过拟合问题
Dialogue: 0,0:31:57.61,0:32:00.67,Default,,0,0,0,,这里也有另一个我们存在的问题
Dialogue: 0,0:32:00.67,0:32:03.13,Default,,0,0,0,,欠拟合是当你的模型不表示且不学习你的数据时出现的问题
Dialogue: 0,0:32:03.13,0:32:04.42,Default,,0,0,0,,欠拟合是当你的模型不表示且不学习你的数据时出现的问题
Dialogue: 0,0:32:04.42,0:32:06.61,Default,,0,0,0,,过拟合是当你的模型学习了足够多的数据但是学错了功能出现的问题
Dialogue: 0,0:32:06.61,0:32:08.41,Default,,0,0,0,,过拟合是当你的模型学习了足够多的数据但是学错了功能出现的问题
Dialogue: 0,0:32:08.41,0:32:09.46,Default,,0,0,0,,因为数据越复杂，模型所学到的功能越多，所产生的错误功能也就越多
Dialogue: 0,0:32:09.46,0:32:12.61,Default,,0,0,0,,因为数据越复杂，模型所学到的功能越多，所产生的错误功能也就越多
Dialogue: 0,0:32:12.61,0:32:18.58,Default,,0,0,0,,因为数据越复杂，模型所学到的功能越多，所产生的错误功能也就越多
Dialogue: 0,0:32:18.58,0:32:20.80,Default,,0,0,0,,因此简而言之这两个问题就是
Dialogue: 0,0:32:20.80,0:32:23.20,Default,,0,0,0,,欠拟合就是你想完成的任务对于你的模型来说太复杂了
Dialogue: 0,0:32:23.20,0:32:25.54,Default,,0,0,0,,欠拟合就是你想完成的任务对于你的模型来说太复杂了
Dialogue: 0,0:32:25.54,0:32:27.19,Default,,0,0,0,,因此如果你的任务对于你的模型来说太复杂
Dialogue: 0,0:32:27.19,0:32:28.66,Default,,0,0,0,,该模型将无法学习
Dialogue: 0,0:32:28.66,0:32:30.31,Default,,0,0,0,,因此你并不想这样
Dialogue: 0,0:32:30.31,0:32:32.29,Default,,0,0,0,,同样的 你也并不想这样
Dialogue: 0,0:32:32.29,0:32:34.12,Default,,0,0,0,,如果你的模型过于复杂
Dialogue: 0,0:32:34.12,0:32:36.04,Default,,0,0,0,,但是你想要完成的任务并不是那么困难的话
Dialogue: 0,0:32:36.04,0:32:37.99,Default,,0,0,0,,这个模型有可能仅仅学到一些令人发笑的功能
Dialogue: 0,0:32:37.99,0:32:39.82,Default,,0,0,0,,这个模型有可能仅仅学到一些令人发笑的功能
Dialogue: 0,0:32:39.82,0:32:42.01,Default,,0,0,0,,这个模型有可能仅仅学到一些令人发笑的功能
Dialogue: 0,0:32:42.01,0:32:43.42,Default,,0,0,0,,因此这样都不会像中间的这些地方一样
Dialogue: 0,0:32:43.42,0:32:46.63,Default,,0,0,0,,因此 根据任务复杂性
Dialogue: 0,0:32:46.63,0:32:48.73,Default,,0,0,0,,你希望拥有一个足够好的模型来实际完成该任务
Dialogue: 0,0:32:48.73,0:32:51.07,Default,,0,0,0,,你希望拥有一个足够好的模型来实际完成该任务
Dialogue: 0,0:32:51.07,0:32:52.96,Default,,0,0,0,,你希望拥有一个足够好的模型来实际生成该任务
Dialogue: 0,0:32:52.96,0:32:56.08,Default,,0,0,0,,因此你希望你的模型有能力生成正确的功能
Dialogue: 0,0:32:56.08,0:32:59.05,Default,,0,0,0,,因此你希望你的模型有能力生成正确的功能
Dialogue: 0,0:32:59.05,0:33:01.53,Default,,0,0,0,,因此你希望你的模型有能力生成正确的功能
Dialogue: 0,0:33:01.53,0:33:03.58,Default,,0,0,0,,但没有太多其他方式来生成可以适应训练数据的模型
Dialogue: 0,0:33:03.58,0:33:06.54,Default,,0,0,0,,但没有太多其他方式来生成可以适应训练数据的模型
Dialogue: 0,0:33:06.54,0:33:10.47,Default,,0,0,0,,举例来说
Dialogue: 0,0:33:10.47,0:33:12.12,Default,,0,0,0,,如果你在谈论模型的复杂度
Dialogue: 0,0:33:12.12,0:33:13.53,Default,,0,0,0,,例子就像线性回归
Dialogue: 0,0:33:13.53,0:33:15.34,Default,,0,0,0,,将是每个模式涉及非常多的东西
Dialogue: 0,0:33:15.34,0:33:18.30,Default,,0,0,0,,例如y=x^3或者y=x-4
Dialogue: 0,0:33:18.30,0:33:20.55,Default,,0,0,0,,所以它不是很好建模
Dialogue: 0,0:33:20.55,0:33:22.74,Default,,0,0,0,,所以它很容易过度拟合
Dialogue: 0,0:33:22.74,0:33:24.03,Default,,0,0,0,,但是例如 如果你有更多的特征 有其他的数值
Dialogue: 0,0:33:24.03,0:33:26.20,Default,,0,0,0,,它就会变得更加复杂
Dialogue: 0,0:33:26.20,0:33:30.03,Default,,0,0,0,,但是换一句话说
Dialogue: 0,0:33:30.03,0:33:33.60,Default,,0,0,0,,你的多层感知器
Dialogue: 0,0:33:33.60,0:33:35.83,Default,,0,0,0,,当你添加更多的层数时 也可以得到更多的表达能力
Dialogue: 0,0:33:35.83,0:33:38.01,Default,,0,0,0,,当你添加更多的层数时 也得到更多的表达能力
Dialogue: 0,0:33:38.01,0:33:41.71,Default,,0,0,0,,因此你就将会有过拟合的危险
Dialogue: 0,0:33:41.71,0:33:43.21,Default,,0,0,0,,因此根据任务复杂度
Dialogue: 0,0:33:43.21,0:33:45.60,Default,,0,0,0,,情感分析往往是一个更简单的任务
Dialogue: 0,0:33:45.60,0:33:47.76,Default,,0,0,0,,而机器翻译往往就会更加复杂
Dialogue: 0,0:33:47.76,0:33:48.99,Default,,0,0,0,,而机器翻译往往就会更加复杂
Dialogue: 0,0:33:48.99,0:33:51.12,Default,,0,0,0,,所以对于难一些的机器翻译 我们就需要更多的参数
Dialogue: 0,0:33:51.12,0:33:52.72,Default,,0,0,0,,所以对于难一些的机器翻译 我们就需要更多的参数
Dialogue: 0,0:33:52.72,0:33:54.82,Default,,0,0,0,,而对于简单一点的情感分析 我们并不需要那么多的参数
Dialogue: 0,0:33:54.82,0:33:56.16,Default,,0,0,0,,而对于简单一点的情感分析 我们并不需要那么多的参数
Dialogue: 0,0:33:56.16,0:33:59.47,Default,,0,0,0,,而对于简单一点的情感分析 我们并不需要那么多的参数
Dialogue: 0,0:33:59.47,0:34:01.38,Default,,0,0,0,,另一件非常重的需要我们考虑的是我们所拥有的数据量
Dialogue: 0,0:34:01.38,0:34:03.12,Default,,0,0,0,,另一件非常重的需要我们考虑的是我们所拥有的数据量
Dialogue: 0,0:34:03.12,0:34:07.14,Default,,0,0,0,,如果你有很少的数据
Dialogue: 0,0:34:07.14,0:34:10.96,Default,,0,0,0,,过拟合对于你来说就是很大的压力
Dialogue: 0,0:34:10.96,0:34:14.20,Default,,0,0,0,,过拟合对于你来说就是很大的压力
Dialogue: 0,0:34:14.20,0:34:15.73,Default,,0,0,0,,但是如果你有很多的数据
Dialogue: 0,0:34:15.73,0:34:17.64,Default,,0,0,0,,过拟合就讲不会成为问题
Dialogue: 0,0:34:17.64,0:34:20.40,Default,,0,0,0,,如此说的原因是
Dialogue: 0,0:34:20.40,0:34:23.13,Default,,0,0,0,,你拥有的数据越多
Dialogue: 0,0:34:23.13,0:34:27.25,Default,,0,0,0,,模型就有越少的可能性产生过拟合的浪费
Dialogue: 0,0:34:27.25,0:34:28.56,Default,,0,0,0,,因为更少的错误的函数
Dialogue: 0,0:34:28.56,0:34:30.69,Default,,0,0,0,,例如
Dialogue: 0,0:34:30.69,0:34:33.76,Default,,0,0,0,,如果你有这些点 我们假设只有最右边的函数是正确的 前两个都是错误的
Dialogue: 0,0:34:33.76,0:34:35.50,Default,,0,0,0,,如果你有这些点 我们假设只有最右边的函数是正确的 前两个都是错误的
Dialogue: 0,0:34:35.50,0:34:37.48,Default,,0,0,0,,如果你有11个点
Dialogue: 0,0:34:37.48,0:34:39.39,Default,,0,0,0,,你就可以看清前两个函数并不能像之前三个点那样 很好的符合这些点的要求
Dialogue: 0,0:34:39.39,0:34:41.13,Default,,0,0,0,,你就可以看清前两个函数并不能像之前三个点那样 很好的符合这些点的要求
Dialogue: 0,0:34:41.13,0:34:43.80,Default,,0,0,0,,你就可以看清前两个函数并不能像之前三个点那样 很好的符合这些点的要求
Dialogue: 0,0:34:43.80,0:34:45.63,Default,,0,0,0,,因为这些特征点实际上代表着真实的特征
Dialogue: 0,0:34:45.63,0:34:47.82,Default,,0,0,0,,因为这些特征点实际上代表着真实的特征
Dialogue: 0,0:34:47.82,0:34:49.56,Default,,0,0,0,,由于错误版本的模型不能适应更多的点
Dialogue: 0,0:34:49.56,0:34:50.95,Default,,0,0,0,,由于错误版本的模型不能适应更多的点
Dialogue: 0,0:34:50.95,0:34:54.06,Default,,0,0,0,,所以你有的点越多，你（最后）选择错误方法的可能性就越低
Dialogue: 0,0:34:54.06,0:34:55.83,Default,,0,0,0,,所以你有的点越多，你（最后）选择错误方法的可能性就越低
Dialogue: 0,0:34:55.83,0:35:01.72,Default,,0,0,0,,所以你有的点越多，你（最后）选择错误方法的可能性就越低
Dialogue: 0,0:35:01.72,0:35:03.76,Default,,0,0,0,,还有一种可以解决拟合问题的办法就是加入
Dialogue: 0,0:35:03.76,0:36:06.13,Default,,0,0,0,,还有一种可以解决拟合问题的办法就是加入偏差(Bias)
Dialogue: 0,0:36:06.13,0:35:09.33,Default,,0,0,0,,类似l1和l2的正则化会帮助你完成这件事
Dialogue: 0,0:35:09.33,0:35:12.17,Default,,0,0,0,,类似l1和l2的正则化会帮助你完成这件事
Dialogue: 0,0:35:12.17,0:35:13.54,Default,,0,0,0,,正则化就是要让你明白你的模型没有必要为了满足所有的特征点而变得非常复杂
Dialogue: 0,0:35:13.54,0:35:15.25,Default,,0,0,0,,正则化就是要让你明白你的模型没有必要为了满足所有的特征点而变得非常复杂
Dialogue: 0,0:35:15.25,0:35:16.72,Default,,0,0,0,,正则化就是要让你明白你的模型没有必要为了满足所有的特征点而变得非常复杂
Dialogue: 0,0:35:16.72,0:35:18.17,Default,,0,0,0,,正则化就是要让你明白你的模型没有必要为了满足所有的特征点而变得非常复杂
Dialogue: 0,0:35:21.17,0:35:23.29,Default,,0,0,0,,你可以计算你（模型）的损失函数
Dialogue: 0,0:35:23.29,0:35:25.21,Default,,0,0,0,,你可以计算你（模型）的损失函数
Dialogue: 0,0:35:25.21,0:35:27.58,Default,,0,0,0,,它可以这样解释
Dialogue: 0,0:35:27.58,0:35:30.34,Default,,0,0,0,,这里w是你的权值的的总和，如果你的w+b变得更高，那这会很不利（损失函数变大）
Dialogue: 0,0:35:30.34,0:35:32.29,Default,,0,0,0,,这里w是你的权值的的总和，如果你的w+b变得更高，那这会很不利（损失函数变大）
Dialogue: 0,0:35:32.29,0:35:34.18,Default,,0,0,0,,所以你给参数赋予更大的权值  你的模型就会变得更差
Dialogue: 0,0:35:34.18,0:35:36.10,Default,,0,0,0,,所以你给参数赋予更大的权值  你的模型就会变得更差
Dialogue: 0,0:35:36.10,0:35:38.59,Default,,0,0,0,,由此带来的是这要求你的模型不要有像之前那么多的单元
Dialogue: 0,0:35:38.59,0:35:41.38,Default,,0,0,0,,由此带来的是这要求你的模型不要有像之前那么多的单元
Dialogue: 0,0:35:41.38,0:35:46.21,Default,,0,0,0,,由此带来的是这要求你的模型不要有像之前那么多的单元
Dialogue: 0,0:35:46.21,0:35:48.37,Default,,0,0,0,,因为每个单元都会增加你的模型的损失
Dialogue: 0,0:35:48.37,0:35:50.23,Default,,0,0,0,,所以如果你没有使用很多的单元去解决问题
Dialogue: 0,0:35:50.23,0:35:52.30,Default,,0,0,0,,所以如果你没有使用很多的单元去解决问题
Dialogue: 0,0:35:52.30,0:35:54.04,Default,,0,0,0,,你将会在损失函数方面有利（减少损失）
Dialogue: 0,0:35:54.04,0:35:58.20,Default,,0,0,0,,你将会在损失函数方面有利（减少损失）
Dialogue: 0,0:35:58.20,0:36:00.52,Default,,0,0,0,,好 现在我要讲一下如何使用离散变量
Dialogue: 0,0:36:00.52,0:36:03.01,Default,,0,0,0,,好 现在我要讲一下如何使用离散变量
Dialogue: 0,0:36:03.01,0:36:04.75,Default,,0,0,0,,当你在解决（之前）香蕉和苹果交换的问题的时候变量是连续的
Dialogue: 0,0:36:04.75,0:36:07.60,Default,,0,0,0,,当你在解决（之前）香蕉和苹果交换的问题的时候变量是连续的
Dialogue: 0,0:36:07.60,0:36:10.45,Default,,0,0,0,,当你在解决（之前）香蕉和苹果交换的问题的时候变量是连续的
Dialogue: 0,0:36:10.45,0:36:12.49,Default,,0,0,0,,你输入的是数字
Dialogue: 0,0:36:12.49,0:36:14.38,Default,,0,0,0,,输出的是另一个数字
Dialogue: 0,0:36:14.38,0:36:16.73,Default,,0,0,0,,但比如当你解决语言类问题的时候
Dialogue: 0,0:36:16.73,0:36:18.19,Default,,0,0,0,,你的输入是字符
Dialogue: 0,0:36:18.19,0:36:22.77,Default,,0,0,0,,我们需要找到一种方法将字符量化成数字
Dialogue: 0,0:36:22.77,0:36:24.31,Default,,0,0,0,,（有一种方法是……）
Dialogue: 0,0:36:24.31,0:36:26.53,Default,,0,0,0,,（我们在这里要做的是……）
Dialogue: 0,0:36:26.53,0:36:30.07,Default,,0,0,0,,我们说Abby会给Cookie Monster一种水果
Dialogue: 0,0:36:30.07,0:36:33.25,Default,,0,0,0,,我们说Abby会给Cookie Monster一种水果
Dialogue: 0,0:36:33.25,0:36:35.41,Default,,0,0,0,,但是这也需要去选择究竟给哪一种水果
Dialogue: 0,0:36:35.41,0:36:37.96,Default,,0,0,0,,但是这也需要去选择究竟给哪一种水果
Dialogue: 0,0:36:37.96,0:36:39.49,Default,,0,0,0,,这就是一个不能量化成数字的关于水果种类的离散变量
Dialogue: 0,0:36:39.49,0:36:41.59,Default,,0,0,0,,这就是一个不能量化成数字的关于水果种类的离散变量
Dialogue: 0,0:36:41.59,0:36:45.64,Default,,0,0,0,,这就是一个不能量化成数字的关于水果种类的离散变量
Dialogue: 0,0:36:45.64,0:36:47.17,Default,,0,0,0,,同时Cookie Monster也要返还一种水果
Dialogue: 0,0:36:47.17,0:36:49.72,Default,,0,0,0,,同时Cookie Monster也要返还一种水果
Dialogue: 0,0:36:49.72,0:36:52.87,Default,,0,0,0,,同时Cookie Monster也要返还一种水果
Dialogue: 0,0:36:52.87,0:36:54.78,Default,,0,0,0,,所以两边都会有离散变量
Dialogue: 0,0:36:55.78,0:36:57.06,Default,,0,0,0,,这样该怎么办呢
Dialogue: 0,0:36:57.06,0:37:01.15,Default,,0,0,0,,现在我们的模型是这样的形式
Dialogue: 0,0:37:01.15,0:37:02.83,Default,,0,0,0,,（模型中）有Abby给出的水果数量和Cookie Monster返还的水果数量
Dialogue: 0,0:37:02.83,0:37:04.96,Default,,0,0,0,,（模型中）有Abby给出的水果数量和Cookie Monster返还的水果数量
Dialogue: 0,0:37:04.96,0:37:08.23,Default,,0,0,0,,（模型中）有Abby给出的水果数量和Cookie Monster返还的水果数量
Dialogue: 0,0:37:08.23,0:37:10.63,Default,,0,0,0,,我们会把它（模型）画成这样
Dialogue: 0,0:37:10.63,0:37:12.67,Default,,0,0,0,,我们会把它（模型）画成这样
Dialogue: 0,0:37:12.67,0:37:13.87,Default,,0,0,0,,基本上这些就是多层感知机的各个层面
Dialogue: 0,0:37:13.87,0:37:16.24,Default,,0,0,0,,基本上这些就是多层感知机的各个层面
Dialogue: 0,0:37:16.24,0:37:18.51,Default,,0,0,0,,但这还不是我们想要的
Dialogue: 0,0:37:18.51,0:37:20.74,Default,,0,0,0,,在这儿我们要加入另一个代表水果种类的变量
Dialogue: 0,0:37:20.74,0:37:22.93,Default,,0,0,0,,在这儿我们要加入另一个代表水果种类的变量
Dialogue: 0,0:37:22.93,0:37:26.41,Default,,0,0,0,,U被定义为Abby给出的水果种类
Dialogue: 0,0:37:26.41,0:37:30.02,Default,,0,0,0,,U被定义为Abby给出的水果种类
Dialogue: 0,0:37:30.02,0:37:32.95,Default,,0,0,0,,V被定义为返还的水果种类
Dialogue: 0,0:37:32.95,0:37:35.92,Default,,0,0,0,,V被定义为返还的水果种类
Dialogue: 0,0:37:35.92,0:37:39.20,Default,,0,0,0,,U可以是（食物）集合中的任意一类
Dialogue: 0,0:37:39.20,0:37:41.63,Default,,0,0,0,,苹果、香蕉、椰子都可以
Dialogue: 0,0:37:41.63,0:37:43.94,Default,,0,0,0,,V也是集合中的一种
Dialogue: 0,0:37:43.94,0:37:47.67,Default,,0,0,0,,人们在网络中所做的事情就是
Dialogue: 0,0:37:47.67,0:37:49.81,Default,,0,0,0,,人们在网络中所做的事情就是
Dialogue: 0,0:37:49.81,0:37:54.43,Default,,0,0,0,,我们需要给每个种类的水果一些参数
Dialogue: 0,0:37:54.43,0:37:56.11,Default,,0,0,0,,我们需要给每个种类的水果一些参数
Dialogue: 0,0:37:56.11,0:37:58.31,Default,,0,0,0,,我们需要给每个种类的水果一些参数
Dialogue: 0,0:37:59.31,0:38:02.38,Default,,0,0,0,,像苹果会被四个参数e1、e2、e3、e4所表示
Dialogue: 0,0:38:02.38,0:38:05.23,Default,,0,0,0,,像苹果会被四个参数e1、e2、e3、e4所表示
Dialogue: 0,0:38:05.23,0:38:07.54,Default,,0,0,0,,不同种类的食物会有不同的参数集合
Dialogue: 0,0:38:07.54,0:38:10.81,Default,,0,0,0,,不同种类的食物会有不同的参数集合
Dialogue: 0,0:38:10.81,0:38:11.91,Default,,0,0,0,,不同种类的食物会有不同的参数集合
Dialogue: 0,0:38:11.91,0:38:14.74,Default,,0,0,0,,当训练模型时这些都会被一起训练
Dialogue: 0,0:38:14.74,0:38:16.64,Default,,0,0,0,,当训练模型时这些都会被一起训练
Dialogue: 0,0:38:17.64,0:38:21.89,Default,,0,0,0,,由于我们知道哪一种食物是需要输入的（给出）
Dialogue: 0,0:38:21.89,0:38:23.68,Default,,0,0,0,,我们直接输入正确的的（参数）
Dialogue: 0,0:38:23.68,0:38:26.71,Default,,0,0,0,,比如我们要给出苹果
Dialogue: 0,0:38:26.71,0:38:28.51,Default,,0,0,0,,我们直接把第一行（数据）
Dialogue: 0,0:38:28.51,0:38:30.81,Default,,0,0,0,,放进词向量U（映射成矢量）
Dialogue: 0,0:38:30.81,0:38:33.70,Default,,0,0,0,,如果你想输入其他（水果）你想给出香蕉
Dialogue: 0,0:38:33.70,0:38:36.11,Default,,0,0,0,,只用把那个（第二行数据）放进词向量U
Dialogue: 0,0:38:36.11,0:38:38.77,Default,,0,0,0,,词向量U就是那个矢量
Dialogue: 0,0:38:39.77,0:38:41.92,Default,,0,0,0,,一组由数字组成的矢量
Dialogue: 0,0:38:41.92,0:38:43.40,Default,,0,0,0,,一组由数字组成的矢量
Dialogue: 0,0:38:43.40,0:38:47.11,Default,,0,0,0,,并用这个矢量作为输入
Dialogue: 0,0:38:47.11,0:38:47.63,Default,,0,0,0,,并用这个矢量作为输入
Dialogue: 0,0:38:48.63,0:38:51.28,Default,,0,0,0,,所以sigmoid函数会有两个输入
Dialogue: 0,0:38:51.28,0:38:53.86,Default,,0,0,0,,香蕉的词向量（映射的矢量）和香蕉的数量
Dialogue: 0,0:38:53.86,0:38:57.37,Default,,0,0,0,,香蕉的词向量（映射的矢量）和香蕉的数量
Dialogue: 0,0:38:57.37,0:38:59.32,Default,,0,0,0,,香蕉的词向量（映射的矢量）和香蕉的数量
Dialogue: 0,0:38:59.32,0:39:02.32,Default,,0,0,0,,香蕉的词向量（映射的矢量）和香蕉的数量
Dialogue: 0,0:39:02.32,0:39:04.09,Default,,0,0,0,,它们是组合的并且和输入单个参数是相同的
Dialogue: 0,0:39:04.09,0:39:07.39,Default,,0,0,0,,它们是组合的并且和输入单个参数是相同的
Dialogue: 0,0:39:07.39,0:39:14.32,Default,,0,0,0,,但你可以了解到各个种类的水果和水果数量之间的关联会被给出
Dialogue: 0,0:39:14.32,0:39:15.76,Default,,0,0,0,,但你可以了解到各个种类的水果和水果数量之间的关联会被给出
Dialogue: 0,0:39:15.76,0:39:18.73,Default,,0,0,0,,但你可以了解到各个种类的水果和水果数量之间的关联会被给出
Dialogue: 0,0:39:18.73,0:39:21.50,Default,,0,0,0,,但你可以了解到各个种类的水果和水果数量之间的关联会被给出
Dialogue: 0,0:39:23.50,0:39:26.32,Default,,0,0,0,,在输出方面则会有一些不同
Dialogue: 0,0:39:26.32,0:39:28.15,Default,,0,0,0,,这是因为我们并不知道给出的是什么水果
Dialogue: 0,0:39:28.15,0:39:30.85,Default,,0,0,0,,这是因为我们并不知道给出的是什么水果
Dialogue: 0,0:39:30.85,0:39:33.58,Default,,0,0,0,,但是我们想要将（给出水果）的可能性最大化
Dialogue: 0,0:39:33.58,0:39:34.14,Default,,0,0,0,,但是我们想要将（给出水果）的可能性最大化
Dialogue: 0,0:39:34.14,0:39:36.85,Default,,0,0,0,,接下来我们有四维的输入矢量
Dialogue: 0,0:39:36.85,0:39:37.93,Default,,0,0,0,,我们有四维的输入矢量
Dialogue: 0,0:39:37.93,0:39:41.55,Default,,0,0,0,,我们将为每一种水果定义一个值
Dialogue: 0,0:39:41.55,0:39:43.48,Default,,0,0,0,,我们将为每一种水果定义一个值
Dialogue: 0,0:39:43.48,0:39:45.88,Default,,0,0,0,,这个我们称之为logits（指数计算出的概率）
Dialogue: 0,0:39:45.88,0:39:47.10,Default,,0,0,0,,因为我们有三种不同的水果
Dialogue: 0,0:39:47.10,0:39:49.48,Default,,0,0,0,,因为我们有三种不同的水果
Dialogue: 0,0:39:49.48,0:39:51.79,Default,,0,0,0,,所以我们在这个矢量中也将有三种不同的值
Dialogue: 0,0:39:51.79,0:39:55.86,Default,,0,0,0,,它更像是这样
Dialogue: 0,0:39:55.86,0:39:57.52,Default,,0,0,0,,在输入它就像是sigmoids的隐藏层的大小
Dialogue: 0,0:39:57.52,0:39:59.67,Default,,0,0,0,,在输入它就像是sigmoids的隐藏层的大小
Dialogue: 0,0:39:59.67,0:40:02.68,Default,,0,0,0,,在输出时每一种不同的水果都会有一个值
Dialogue: 0,0:40:02.68,0:40:05.77,Default,,0,0,0,,在输出时每一种不同的水果都会有一个值
Dialogue: 0,0:40:05.77,0:40:07.72,Default,,0,0,0,,v1是苹果 v2是香蕉
Dialogue: 0,0:40:07.72,0:40:09.64,Default,,0,0,0,,v3是椰子
Dialogue: 0,0:40:09.64,0:40:11.82,Default,,0,0,0,,之后我们会把这个值转换成概率
Dialogue: 0,0:40:11.82,0:40:13.86,Default,,0,0,0,,之后我们会把这个值转换成概率
Dialogue: 0,0:40:13.86,0:40:15.94,Default,,0,0,0,,我们会使用softmax函数来完成
Dialogue: 0,0:40:15.94,0:40:19.18,Default,,0,0,0,,（softmax函数指的是）用每一个e为底d的指数函数
Dialogue: 0,0:40:19.18,0:40:21.55,Default,,0,0,0,,（softmax函数指的是）用每一个e为底d的指数函数
Dialogue: 0,0:40:21.55,0:40:23.41,Default,,0,0,0,,除以可能的logits的总和
Dialogue: 0,0:40:23.41,0:40:25.51,Default,,0,0,0,,所以我们会得到一个的指数函数并除以其他logits的总和
Dialogue: 0,0:40:25.51,0:40:29.64,Default,,0,0,0,,所以我们会得到一个的指数函数并除以其他logits的总和
Dialogue: 0,0:40:29.64,0:40:30.55,Default,,0,0,0,,然后算出所有的数字（Pi）
Dialogue: 0,0:40:30.55,0:40:33.25,Default,,0,0,0,,然后算出所有的数字（Pi）
Dialogue: 0,0:40:33.25,0:40:35.50,Default,,0,0,0,,这个函数有一个很好的性质
Dialogue: 0,0:40:35.50,0:40:38.86,Default,,0,0,0,,它得出的所有值（Pi）都会在0和1之间
Dialogue: 0,0:40:38.86,0:40:41.48,Default,,0,0,0,,并且总和是1
Dialogue: 0,0:40:41.48,0:40:43.51,Default,,0,0,0,,它可以估计出（返还水果种类的）概率
Dialogue: 0,0:40:43.51,0:40:47.14,Default,,0,0,0,,它可以估计出（返还水果种类的）概率
Dialogue: 0,0:40:47.14,0:40:50.31,Default,,0,0,0,,通过这个我们可以发现在这个例子中Cookie Monster返还了一个苹果
Dialogue: 0,0:40:50.31,0:40:54.28,Default,,0,0,0,,通过这个我们可以发现在这个例子中Cookie Monster返还了一个苹果
Dialogue: 0,0:40:54.28,0:40:57.79,Default,,0,0,0,,通过这个我们可以发现在这个例子中Cookie Monster返还了一个苹果
Dialogue: 0,0:40:57.79,0:41:00.47,Default,,0,0,0,,因为这个除法（softmax函数）的原因
Dialogue: 0,0:41:02.47,0:41:03.22,Default,,0,0,0,,这个模型可以实现自我的更新
Dialogue: 0,0:41:03.22,0:41:05.14,Default,,0,0,0,,这个模型可以实现自我的更新
Dialogue: 0,0:41:05.14,0:41:07.27,Default,,0,0,0,,苹果的几率会越来越高
Dialogue: 0,0:41:07.27,0:41:09.67,Default,,0,0,0,,苹果的几率会越来越高
Dialogue: 0,0:41:09.67,0:41:14.44,Default,,0,0,0,,其他种类的水果的概率则会越来越低
Dialogue: 0,0:41:14.44,0:41:16.15,Default,,0,0,0,,现在我们可以建立的模型
Dialogue: 0,0:41:16.15,0:41:19.27,Default,,0,0,0,,我们有（输入）水果的数量和种类
Dialogue: 0,0:41:19.27,0:41:20.50,Default,,0,0,0,,（模型）将会输出cookie monster返还的水果数量和种类
Dialogue: 0,0:41:20.50,0:41:21.76,Default,,0,0,0,,（模型）将会输出cookie monster返还的水果数量和种类
Dialogue: 0,0:41:21.76,0:41:25.48,Default,,0,0,0,,（模型）将会输出cookie monster返还的水果数量和种类
Dialogue: 0,0:41:25.48,0:41:28.58,Default,,0,0,0,,总结一下
Dialogue: 0,0:41:29.58,0:41:31.78,Default,,0,0,0,,我们学习了一个现在并不使用
Dialogue: 0,0:41:31.78,0:41:34.23,Default,,0,0,0,,但以前曾经频繁使用过的模型
Dialogue: 0,0:41:34.23,0:41:36.76,Default,,0,0,0,,（这个模型）叫做多层感知器
Dialogue: 0,0:41:36.76,0:41:40.11,Default,,0,0,0,,我们还讨论了如何处理连续输入变量
Dialogue: 0,0:41:40.11,0:41:42.57,Default,,0,0,0,,我们还讨论了如何处理连续输入变量
Dialogue: 0,0:41:42.57,0:41:44.20,Default,,0,0,0,,怎样使用离散变量类似词向量
Dialogue: 0,0:41:44.20,0:41:47.23,Default,,0,0,0,,怎样使用离散变量类似词向量
Dialogue: 0,0:41:47.23,0:41:50.76,Default,,0,0,0,,怎样使用连续变量的线性组合
Dialogue: 0,0:41:50.76,0:41:52.59,Default,,0,0,0,,和用离散变量计算softmax函数
Dialogue: 0,0:41:52.59,0:41:55.03,Default,,0,0,0,,和用离散变量计算softmax函数
Dialogue: 0,0:41:55.03,0:42:01.73,Default,,0,0,0,,好的谢谢大家
Dialogue: 0,0:42:01.73,0:42:05.01,Default,,0,0,0,,[Applause]
